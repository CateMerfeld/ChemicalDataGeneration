Using device: cuda
--------------------------
--------------------------
New run with hyperparameters:
batch_size  :  16
epochs  :  500
learning_rate  :  1e-05
Saved best model at epoch 1
Saved best model at epoch 2
Saved best model at epoch 3
Saved best model at epoch 4
Saved best model at epoch 5
Saved best model at epoch 6
Saved best model at epoch 8
Saved best model at epoch 10
Epoch[10/500]:
   Training loss: 6.721440202746635e-05
   Validation loss: 0.0008363850845073931
-------------------------------------------
Saved best model at epoch 11
Saved best model at epoch 12
Epoch 00018: reducing learning rate of group 0 to 1.0000e-06.
Saved best model at epoch 19
Saved best model at epoch 20
Epoch[20/500]:
   Training loss: 3.203767526650836e-07
   Validation loss: 0.0006442709374397742
-------------------------------------------
Saved best model at epoch 21
Saved best model at epoch 22
Saved best model at epoch 23
Saved best model at epoch 24
Saved best model at epoch 25
Saved best model at epoch 27
Saved best model at epoch 29
Saved best model at epoch 30
Epoch[30/500]:
   Training loss: 3.597863521413558e-08
   Validation loss: 0.0005779532436347325
-------------------------------------------
Saved best model at epoch 31
Saved best model at epoch 36
Epoch[40/500]:
   Training loss: 2.4048341899920445e-08
   Validation loss: 0.000584870277345651
-------------------------------------------
Epoch 00042: reducing learning rate of group 0 to 1.0000e-07.
Validation loss has not improved in 10 epochs. Stopping training at epoch 46.
-------------------------------------------
-------------------------------------------
Dataset:  carls
Target Embeddings:  ChemNet
-------------------------------------------
-------------------------------------------
Encoder(
  (encoder): Sequential(
    (0): Linear(in_features=1676, out_features=1548, bias=True)
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
    (2): Linear(in_features=1548, out_features=1420, bias=True)
    (3): LeakyReLU(negative_slope=0.01, inplace=True)
    (4): Linear(in_features=1420, out_features=1292, bias=True)
    (5): LeakyReLU(negative_slope=0.01, inplace=True)
    (6): Linear(in_features=1292, out_features=1164, bias=True)
    (7): LeakyReLU(negative_slope=0.01, inplace=True)
    (8): Linear(in_features=1164, out_features=1036, bias=True)
    (9): LeakyReLU(negative_slope=0.01, inplace=True)
    (10): Linear(in_features=1036, out_features=908, bias=True)
    (11): LeakyReLU(negative_slope=0.01, inplace=True)
    (12): Linear(in_features=908, out_features=780, bias=True)
    (13): LeakyReLU(negative_slope=0.01, inplace=True)
    (14): Linear(in_features=780, out_features=652, bias=True)
    (15): LeakyReLU(negative_slope=0.01, inplace=True)
    (16): Linear(in_features=652, out_features=512, bias=True)
  )
)
-------------------------------------------
-------------------------------------------