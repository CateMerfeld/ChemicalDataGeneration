Using device: cuda
--------------------------
--------------------------
New run with hyperparameters:
batch_size  :  32
epochs  :  500
learning_rate  :  1e-06
Saved best model at epoch 1
Saved best model at epoch 2
Saved best model at epoch 3
Saved best model at epoch 4
Saved best model at epoch 5
Saved best model at epoch 6
Saved best model at epoch 7
Saved best model at epoch 8
Saved best model at epoch 9
Saved best model at epoch 10
Epoch[10/500]:
   Training loss: 8.770037710348345e-05
   Validation loss: 7.536527267222545e-05
-------------------------------------------
Saved best model at epoch 12
Saved best model at epoch 13
Saved best model at epoch 15
Saved best model at epoch 16
Saved best model at epoch 20
Epoch[20/500]:
   Training loss: 3.785604005654639e-05
   Validation loss: 3.8193165847070335e-05
-------------------------------------------
Saved best model at epoch 21
Saved best model at epoch 23
Saved best model at epoch 25
Saved best model at epoch 28
Saved best model at epoch 29
Epoch[30/500]:
   Training loss: 2.6672224880955242e-05
   Validation loss: 3.0376452688697412e-05
-------------------------------------------
Saved best model at epoch 32
Saved best model at epoch 33
Saved best model at epoch 34
Saved best model at epoch 37
Saved best model at epoch 39
Epoch[40/500]:
   Training loss: 2.0767826373236485e-05
   Validation loss: 1.7773758133016757e-05
-------------------------------------------
Saved best model at epoch 45
Saved best model at epoch 50
Epoch[50/500]:
   Training loss: 1.4395750640671417e-05
   Validation loss: 1.4892997261666033e-05
-------------------------------------------
Saved best model at epoch 54
Saved best model at epoch 56
Saved best model at epoch 57
Saved best model at epoch 60
Epoch[60/500]:
   Training loss: 1.1147951482986176e-05
   Validation loss: 1.2029969703554609e-05
-------------------------------------------
Saved best model at epoch 66
Saved best model at epoch 69
Epoch[70/500]:
   Training loss: 1.2311213119675852e-05
   Validation loss: 2.0727295238571217e-05
-------------------------------------------
Saved best model at epoch 74
Saved best model at epoch 80
Epoch[80/500]:
   Training loss: 9.200824141934527e-06
   Validation loss: 1.0999257712334274e-05
-------------------------------------------
Saved best model at epoch 89
Epoch[90/500]:
   Training loss: 9.814515441845274e-06
   Validation loss: 1.6869240898264753e-05
-------------------------------------------
Saved best model at epoch 95
Saved best model at epoch 97
Epoch[100/500]:
   Training loss: 8.702936288838355e-06
   Validation loss: 1.0297866497984584e-05
-------------------------------------------
Saved best model at epoch 103
Saved best model at epoch 104
Saved best model at epoch 106
Epoch[110/500]:
   Training loss: 6.798819778040023e-06
   Validation loss: 1.307596943115445e-05
-------------------------------------------
Saved best model at epoch 114
Epoch[120/500]:
   Training loss: 7.78272925703775e-06
   Validation loss: 9.615563132178037e-06
-------------------------------------------
Validation loss has not improved in 10 epochs. Stopping training at epoch 124.
-------------------------------------------
-------------------------------------------
Dataset:  IMS
Target Embeddings:  ChemNet
-------------------------------------------
-------------------------------------------
Encoder(
  (encoder): Sequential(
    (0): Linear(in_features=1676, out_features=1548, bias=True)
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
    (2): Linear(in_features=1548, out_features=1420, bias=True)
    (3): LeakyReLU(negative_slope=0.01, inplace=True)
    (4): Linear(in_features=1420, out_features=1292, bias=True)
    (5): LeakyReLU(negative_slope=0.01, inplace=True)
    (6): Linear(in_features=1292, out_features=1164, bias=True)
    (7): LeakyReLU(negative_slope=0.01, inplace=True)
    (8): Linear(in_features=1164, out_features=1036, bias=True)
    (9): LeakyReLU(negative_slope=0.01, inplace=True)
    (10): Linear(in_features=1036, out_features=908, bias=True)
    (11): LeakyReLU(negative_slope=0.01, inplace=True)
    (12): Linear(in_features=908, out_features=780, bias=True)
    (13): LeakyReLU(negative_slope=0.01, inplace=True)
    (14): Linear(in_features=780, out_features=652, bias=True)
    (15): LeakyReLU(negative_slope=0.01, inplace=True)
    (16): Linear(in_features=652, out_features=512, bias=True)
  )
)
-------------------------------------------
-------------------------------------------