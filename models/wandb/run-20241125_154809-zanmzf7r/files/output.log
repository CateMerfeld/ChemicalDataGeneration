Using device: cuda
--------------------------
--------------------------
New run with hyperparameters:
batch_size  :  64
epochs  :  100
learning_rate  :  0.0001
Saved best model at epoch 1
Saved best model at epoch 2
Saved best model at epoch 3
Saved best model at epoch 4
Saved best model at epoch 5
Saved best model at epoch 6
Saved best model at epoch 7
Saved best model at epoch 9
Saved best model at epoch 10
Epoch[10/100]:
   Training loss: 0.0003370283025339675
   Validation loss: 0.0009127445273226226
-------------------------------------------
Saved best model at epoch 13
Saved best model at epoch 17
Saved best model at epoch 18
Epoch[20/100]:
   Training loss: 0.00021680019802579334
   Validation loss: 0.0008326412423067443
-------------------------------------------
Saved best model at epoch 25
Saved best model at epoch 28
Epoch[30/100]:
   Training loss: 7.310207107595555e-05
   Validation loss: 0.0008259262957661073
-------------------------------------------
Saved best model at epoch 36
Saved best model at epoch 39
Epoch[40/100]:
   Training loss: 0.00013638432644285338
   Validation loss: 0.0008557908580564649
-------------------------------------------
Saved best model at epoch 47
Epoch[50/100]:
   Training loss: 8.11806957897785e-06
   Validation loss: 0.0006265125539206963
-------------------------------------------
Validation loss has not improved in 10 epochs. Stopping training.
-------------------------------------------
-------------------------------------------
Dataset:  MNIST
Target Embeddings:  ChemNet
-------------------------------------------
-------------------------------------------
Encoder(
  (encoder): Sequential(
    (0): Linear(in_features=784, out_features=716, bias=True)
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
    (2): Linear(in_features=716, out_features=648, bias=True)
    (3): LeakyReLU(negative_slope=0.01, inplace=True)
    (4): Linear(in_features=648, out_features=580, bias=True)
    (5): LeakyReLU(negative_slope=0.01, inplace=True)
    (6): Linear(in_features=580, out_features=512, bias=True)
  )
)
-------------------------------------------
-------------------------------------------