Using device: cuda
--------------------------
--------------------------
New run with hyperparameters:
batch_size  :  32
epochs  :  100
learning_rate  :  0.01
Saved best model at epoch 0
Epoch[1/100]:
   Training loss: 9389166.225109592
   Validation loss: 133351.5579028257
-------------------------------------------
Epoch 00007: reducing learning rate of group 0 to 1.0000e-03.
Epoch[10/100]:
   Training loss: 153755.58520332273
   Validation loss: 158109.74713856235
-------------------------------------------
Validation loss has not improved in 10 epochs. Stopping training at epoch 11.
Validation loss has not improved in 10 epochs. Stopping training at epoch 12.
Validation loss has not improved in 10 epochs. Stopping training at epoch 13.
Validation loss has not improved in 10 epochs. Stopping training at epoch 14.
Validation loss has not improved in 10 epochs. Stopping training at epoch 15.
Validation loss has not improved in 10 epochs. Stopping training at epoch 16.
Validation loss has not improved in 10 epochs. Stopping training at epoch 17.
Validation loss has not improved in 10 epochs. Stopping training at epoch 18.
Validation loss has not improved in 10 epochs. Stopping training at epoch 19.
Validation loss has not improved in 10 epochs. Stopping training at epoch 20.
Validation loss has not improved in 10 epochs. Stopping training at epoch 21.
Validation loss has not improved in 10 epochs. Stopping training at epoch 22.
Validation loss has not improved in 10 epochs. Stopping training at epoch 23.
Validation loss has not improved in 10 epochs. Stopping training at epoch 24.
Validation loss has not improved in 10 epochs. Stopping training at epoch 25.
Validation loss has not improved in 10 epochs. Stopping training at epoch 26.
Validation loss has not improved in 10 epochs. Stopping training at epoch 27.
Validation loss has not improved in 10 epochs. Stopping training at epoch 28.
Validation loss has not improved in 10 epochs. Stopping training at epoch 29.
Validation loss has not improved in 10 epochs. Stopping training at epoch 30.
Validation loss has not improved in 10 epochs. Stopping training at epoch 31.
Validation loss has not improved in 10 epochs. Stopping training at epoch 32.
Validation loss has not improved in 10 epochs. Stopping training at epoch 33.
Validation loss has not improved in 10 epochs. Stopping training at epoch 34.
Validation loss has not improved in 10 epochs. Stopping training at epoch 35.
Validation loss has not improved in 10 epochs. Stopping training at epoch 36.
Validation loss has not improved in 10 epochs. Stopping training at epoch 37.
Validation loss has not improved in 10 epochs. Stopping training at epoch 38.
Validation loss has not improved in 10 epochs. Stopping training at epoch 39.
Validation loss has not improved in 10 epochs. Stopping training at epoch 40.
Validation loss has not improved in 10 epochs. Stopping training at epoch 41.
Validation loss has not improved in 10 epochs. Stopping training at epoch 42.
Validation loss has not improved in 10 epochs. Stopping training at epoch 43.
Validation loss has not improved in 10 epochs. Stopping training at epoch 44.
Validation loss has not improved in 10 epochs. Stopping training at epoch 45.
Validation loss has not improved in 10 epochs. Stopping training at epoch 46.
Validation loss has not improved in 10 epochs. Stopping training at epoch 47.
Validation loss has not improved in 10 epochs. Stopping training at epoch 48.
Validation loss has not improved in 10 epochs. Stopping training at epoch 49.
Validation loss has not improved in 10 epochs. Stopping training at epoch 50.
Validation loss has not improved in 10 epochs. Stopping training at epoch 51.
Validation loss has not improved in 10 epochs. Stopping training at epoch 52.
Validation loss has not improved in 10 epochs. Stopping training at epoch 53.
Validation loss has not improved in 10 epochs. Stopping training at epoch 54.
Validation loss has not improved in 10 epochs. Stopping training at epoch 55.
Validation loss has not improved in 10 epochs. Stopping training at epoch 56.
Validation loss has not improved in 10 epochs. Stopping training at epoch 57.
Unexpected exception formatting exception. Falling back to standard exception
Traceback (most recent call last):
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/IPython/core/interactiveshell.py", line 3508, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "/tmp/ipykernel_118447/2174215164.py", line 27, in <module>
    train_generator(
  File "/tmp/ipykernel_118447/76341869.py", line 143, in train_generator
    train_predicted_carls, train_output_name_encodings, _, _ = f.predict_embeddings(train_dataset, model, device, criterion)
  File "/home/cmdunham/ChemicalDataGeneration/models/functions.py", line 311, in predict_embeddings
    batch_predicted_embeddings = model(batch)
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cmdunham/ChemicalDataGeneration/models/functions.py", line 1358, in forward
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/torch/nn/modules/container.py", line 215, in forward
    input = module(input)
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 774, in forward
    return F.leaky_relu(input, self.negative_slope, self.inplace)
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/torch/nn/functional.py", line 1644, in leaky_relu
    result = torch._C._nn.leaky_relu_(input, negative_slope)
KeyboardInterrupt
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/IPython/core/interactiveshell.py", line 2105, in showtraceback
    stb = self.InteractiveTB.structured_traceback(
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/IPython/core/ultratb.py", line 1396, in structured_traceback
    return FormattedTB.structured_traceback(
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/IPython/core/ultratb.py", line 1287, in structured_traceback
    return VerboseTB.structured_traceback(
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/IPython/core/ultratb.py", line 1140, in structured_traceback
    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/IPython/core/ultratb.py", line 1055, in format_exception_as_a_whole
    frames.append(self.format_record(record))
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/IPython/core/ultratb.py", line 955, in format_record
    frame_info.lines, Colors, self.has_colors, lvals
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/IPython/core/ultratb.py", line 778, in lines
    return self._sd.lines
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/stack_data/utils.py", line 145, in cached_property_wrapper
    value = obj.__dict__[self.func.__name__] = self.func(obj)
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/stack_data/core.py", line 734, in lines
    pieces = self.included_pieces
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/stack_data/utils.py", line 145, in cached_property_wrapper
    value = obj.__dict__[self.func.__name__] = self.func(obj)
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/stack_data/core.py", line 681, in included_pieces
    pos = scope_pieces.index(self.executing_piece)
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/stack_data/utils.py", line 145, in cached_property_wrapper
    value = obj.__dict__[self.func.__name__] = self.func(obj)
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/stack_data/core.py", line 660, in executing_piece
    return only(
  File "/home/cmdunham/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/executing/executing.py", line 116, in only
    raise NotOneValueFound('Expected one value, found 0')
executing.executing.NotOneValueFound: Expected one value, found 0