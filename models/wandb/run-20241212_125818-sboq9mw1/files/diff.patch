diff --git a/models/carl_encoder.ipynb b/models/carl_encoder.ipynb
index bad0ed71..ec1e38e9 100644
--- a/models/carl_encoder.ipynb
+++ b/models/carl_encoder.ipynb
@@ -34,27 +34,21 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 19,
    "metadata": {},
    "outputs": [],
    "source": [
-    "file_path = '../data/name_smiles_embedding_file.csv'\n",
-    "name_smiles_embedding_df = pd.read_csv(file_path)\n",
-    "\n",
-    "file_path = '/mnt/usb/cmdunham/MoNA_embeddings_big_df.csv'\n",
-    "mass_spec_embeddings = pd.read_csv(file_path)\n",
-    "mass_spec_embeddings = mass_spec_embeddings.rename(columns={\n",
-    "    'METHYL PROPIONATE': 'Methyl Propionate', 'DIETHYL MALEATE':'Diethyl Maleate'\n",
-    "    })\n",
-    "\n",
-    "file_path = '../data/mass_spec_encoder_generated_embeddings.csv'\n",
-    "mass_spec_encoder_generated_embeddings = pd.read_csv(file_path)\n",
-    "mass_spec_encoder_generated_embeddings = mass_spec_encoder_generated_embeddings.drop('Unnamed: 0', axis=1)"
+    "file_path = '/mnt/usb/cmdunham/preprocessed_ims_data/train_carls.csv'\n",
+    "train_carls = pd.read_csv(file_path)\n",
+    "file_path = '/mnt/usb/cmdunham/preprocessed_ims_data/val_carls.csv'\n",
+    "val_carls = pd.read_csv(file_path)\n",
+    "file_path='/mnt/usb/cmdunham/preprocessed_ims_data/test_carls.csv'\n",
+    "test_carls = pd.read_csv(file_path)"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": null,
    "metadata": {},
    "outputs": [
     {
@@ -78,131 +72,617 @@
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
-       "      <th>Name</th>\n",
-       "      <th>SMILES</th>\n",
-       "      <th>embedding</th>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>Unnamed: 0</th>\n",
-       "      <th></th>\n",
-       "      <th></th>\n",
-       "      <th></th>\n",
+       "      <th>index</th>\n",
+       "      <th>p_184</th>\n",
+       "      <th>p_185</th>\n",
+       "      <th>p_186</th>\n",
+       "      <th>p_187</th>\n",
+       "      <th>p_188</th>\n",
+       "      <th>p_189</th>\n",
+       "      <th>p_190</th>\n",
+       "      <th>p_191</th>\n",
+       "      <th>p_192</th>\n",
+       "      <th>...</th>\n",
+       "      <th>n_1021</th>\n",
+       "      <th>Label</th>\n",
+       "      <th>DEB</th>\n",
+       "      <th>DEM</th>\n",
+       "      <th>DMMP</th>\n",
+       "      <th>DPM</th>\n",
+       "      <th>DtBP</th>\n",
+       "      <th>JP8</th>\n",
+       "      <th>MES</th>\n",
+       "      <th>TEPO</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
-       "      <th>BKG</th>\n",
-       "      <td>background</td>\n",
-       "      <td>NaN</td>\n",
-       "      <td>NaN</td>\n",
+       "      <th>0</th>\n",
+       "      <td>1297539</td>\n",
+       "      <td>-12.0</td>\n",
+       "      <td>-14.0</td>\n",
+       "      <td>-16.0</td>\n",
+       "      <td>-20.0</td>\n",
+       "      <td>-21.0</td>\n",
+       "      <td>-22.0</td>\n",
+       "      <td>-22.0</td>\n",
+       "      <td>-24.0</td>\n",
+       "      <td>-25.0</td>\n",
+       "      <td>...</td>\n",
+       "      <td>-8.0</td>\n",
+       "      <td>DtBP</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>1.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
-       "      <th>DEM</th>\n",
-       "      <td>Diethyl Malonate</td>\n",
-       "      <td>CCOC(=O)CC(=O)OCC</td>\n",
-       "      <td>[0.3809721, 0.0005454041, 0.25539744, -0.24272...</td>\n",
+       "      <th>1</th>\n",
+       "      <td>1297539</td>\n",
+       "      <td>-12.0</td>\n",
+       "      <td>-10.0</td>\n",
+       "      <td>-7.0</td>\n",
+       "      <td>-4.0</td>\n",
+       "      <td>1.0</td>\n",
+       "      <td>3.0</td>\n",
+       "      <td>7.0</td>\n",
+       "      <td>6.0</td>\n",
+       "      <td>8.0</td>\n",
+       "      <td>...</td>\n",
+       "      <td>15.0</td>\n",
+       "      <td>DtBP</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>1.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
-       "      <th>DEB</th>\n",
-       "      <td>1,2,3,4-Diepoxybutane</td>\n",
-       "      <td>C1C(O1)C2CO2</td>\n",
-       "      <td>[0.06318794, 0.009022224, 0.42160064, 0.195722...</td>\n",
+       "      <th>2</th>\n",
+       "      <td>1344903</td>\n",
+       "      <td>2.0</td>\n",
+       "      <td>2.0</td>\n",
+       "      <td>2.0</td>\n",
+       "      <td>1.0</td>\n",
+       "      <td>2.0</td>\n",
+       "      <td>2.0</td>\n",
+       "      <td>1.0</td>\n",
+       "      <td>1.0</td>\n",
+       "      <td>-2.0</td>\n",
+       "      <td>...</td>\n",
+       "      <td>-7.0</td>\n",
+       "      <td>DMMP</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>1.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
-       "      <th>MES</th>\n",
-       "      <td>2-(N-morpholino)ethanesulfonic acid</td>\n",
-       "      <td>C1COCCN1CCS(=O)(=O)O</td>\n",
-       "      <td>[-0.32520828, 0.009838344, -0.15108332, 0.2845...</td>\n",
+       "      <th>3</th>\n",
+       "      <td>1344903</td>\n",
+       "      <td>2.0</td>\n",
+       "      <td>6.0</td>\n",
+       "      <td>11.0</td>\n",
+       "      <td>17.0</td>\n",
+       "      <td>24.0</td>\n",
+       "      <td>27.0</td>\n",
+       "      <td>30.0</td>\n",
+       "      <td>31.0</td>\n",
+       "      <td>31.0</td>\n",
+       "      <td>...</td>\n",
+       "      <td>16.0</td>\n",
+       "      <td>DMMP</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>1.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
-       "      <th>DMMP</th>\n",
-       "      <td>Dimethyl methylphosphonate</td>\n",
-       "      <td>COP(=O)(C)OC</td>\n",
-       "      <td>[0.12106811, 0.00294244, -0.14450458, 0.072665...</td>\n",
+       "      <th>4</th>\n",
+       "      <td>1221071</td>\n",
+       "      <td>10.0</td>\n",
+       "      <td>12.0</td>\n",
+       "      <td>15.0</td>\n",
+       "      <td>14.0</td>\n",
+       "      <td>17.0</td>\n",
+       "      <td>19.0</td>\n",
+       "      <td>22.0</td>\n",
+       "      <td>23.0</td>\n",
+       "      <td>26.0</td>\n",
+       "      <td>...</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>TEPO</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>0.0</td>\n",
+       "      <td>1.0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
+       "<p>5 rows × 1686 columns</p>\n",
        "</div>"
       ],
       "text/plain": [
-       "                                           Name                SMILES  \\\n",
-       "Unnamed: 0                                                              \n",
-       "BKG                                  background                   NaN   \n",
-       "DEM                            Diethyl Malonate     CCOC(=O)CC(=O)OCC   \n",
-       "DEB                       1,2,3,4-Diepoxybutane          C1C(O1)C2CO2   \n",
-       "MES         2-(N-morpholino)ethanesulfonic acid  C1COCCN1CCS(=O)(=O)O   \n",
-       "DMMP                 Dimethyl methylphosphonate          COP(=O)(C)OC   \n",
+       "     index  p_184  p_185  p_186  p_187  p_188  p_189  p_190  p_191  p_192  \\\n",
+       "0  1297539  -12.0  -14.0  -16.0  -20.0  -21.0  -22.0  -22.0  -24.0  -25.0   \n",
+       "1  1297539  -12.0  -10.0   -7.0   -4.0    1.0    3.0    7.0    6.0    8.0   \n",
+       "2  1344903    2.0    2.0    2.0    1.0    2.0    2.0    1.0    1.0   -2.0   \n",
+       "3  1344903    2.0    6.0   11.0   17.0   24.0   27.0   30.0   31.0   31.0   \n",
+       "4  1221071   10.0   12.0   15.0   14.0   17.0   19.0   22.0   23.0   26.0   \n",
        "\n",
-       "                                                    embedding  \n",
-       "Unnamed: 0                                                     \n",
-       "BKG                                                       NaN  \n",
-       "DEM         [0.3809721, 0.0005454041, 0.25539744, -0.24272...  \n",
-       "DEB         [0.06318794, 0.009022224, 0.42160064, 0.195722...  \n",
-       "MES         [-0.32520828, 0.009838344, -0.15108332, 0.2845...  \n",
-       "DMMP        [0.12106811, 0.00294244, -0.14450458, 0.072665...  "
+       "   ...  n_1021  Label  DEB  DEM  DMMP  DPM  DtBP  JP8  MES  TEPO  \n",
+       "0  ...    -8.0   DtBP  0.0  0.0   0.0  0.0   1.0  0.0  0.0   0.0  \n",
+       "1  ...    15.0   DtBP  0.0  0.0   0.0  0.0   1.0  0.0  0.0   0.0  \n",
+       "2  ...    -7.0   DMMP  0.0  0.0   1.0  0.0   0.0  0.0  0.0   0.0  \n",
+       "3  ...    16.0   DMMP  0.0  0.0   1.0  0.0   0.0  0.0  0.0   0.0  \n",
+       "4  ...     0.0   TEPO  0.0  0.0   0.0  0.0   0.0  0.0  0.0   1.0  \n",
+       "\n",
+       "[5 rows x 1686 columns]"
       ]
      },
-     "execution_count": 3,
      "metadata": {},
-     "output_type": "execute_result"
+     "output_type": "display_data"
     }
    ],
    "source": [
-    "# set the df index to be the chemical abbreviations in col 'Unnamed: 0'\n",
-    "name_smiles_embedding_df.set_index('Unnamed: 0', inplace=True)\n",
-    "name_smiles_embedding_df.head()"
+    "train_carls.head()"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": 34,
    "metadata": {},
    "outputs": [],
    "source": [
-    "embedding_floats = []\n",
-    "for chem_name in name_smiles_embedding_df.index:\n",
-    "    if chem_name == 'BKG':\n",
-    "        embedding_floats.append(None)\n",
-    "    else:\n",
-    "        embedding_float = name_smiles_embedding_df['embedding'][chem_name].split('[')[1]\n",
-    "        embedding_float = embedding_float.split(']')[0]\n",
-    "        embedding_float = [np.float32(num) for num in embedding_float.split(',')]\n",
-    "        embedding_floats.append(embedding_float)\n",
+    "file_path = '../data/name_smiles_embedding_file.csv'\n",
+    "name_smiles_embedding_df = pd.read_csv(file_path)\n",
     "\n",
-    "name_smiles_embedding_df['Embedding Floats'] = embedding_floats"
-   ]
-  },
-  {
-   "cell_type": "markdown",
-   "metadata": {},
-   "source": [
-    "## Setting up GPU:\n",
-    "---"
+    "file_path = '/mnt/usb/cmdunham/MoNA_embeddings_big_df.csv'\n",
+    "mass_spec_embeddings = pd.read_csv(file_path)\n",
+    "mass_spec_embeddings = mass_spec_embeddings.rename(columns={\n",
+    "    'METHYL PROPIONATE': 'Methyl Propionate', 'DIETHYL MALEATE':'Diethyl Maleate'\n",
+    "    })\n",
+    "\n",
+    "file_path = '../data/mass_spec_encoder_generated_embeddings.csv'\n",
+    "mass_spec_encoder_generated_embeddings = pd.read_csv(file_path)\n",
+    "mass_spec_encoder_generated_embeddings = mass_spec_encoder_generated_embeddings.drop('Unnamed: 0', axis=1)"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": 45,
    "metadata": {},
    "outputs": [
     {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Selected GPU ID: 0\n",
-      "  Name: NVIDIA GeForce RTX 4090\n",
-      "  Memory Free: 21682.0 MB\n",
-      "  Memory Used: 2534.0 MB\n",
-      "  GPU Load: 98.00%\n",
-      "Current device ID:  cuda:0\n",
-      "PyTorch current device ID: 0\n",
-      "PyTorch current device name: NVIDIA GeForce RTX 4090\n"
-     ]
-    }
-   ],
-   "source": [
-    "if torch.cuda.is_available():\n",
-    "    # Get the list of GPUs\n",
+     "data": {
+      "text/html": [
+       "<div>\n",
+       "<style scoped>\n",
+       "    .dataframe tbody tr th:only-of-type {\n",
+       "        vertical-align: middle;\n",
+       "    }\n",
+       "\n",
+       "    .dataframe tbody tr th {\n",
+       "        vertical-align: top;\n",
+       "    }\n",
+       "\n",
+       "    .dataframe thead th {\n",
+       "        text-align: right;\n",
+       "    }\n",
+       "</style>\n",
+       "<table border=\"1\" class=\"dataframe\">\n",
+       "  <thead>\n",
+       "    <tr style=\"text-align: right;\">\n",
+       "      <th></th>\n",
+       "      <th>Succinic acid</th>\n",
+       "      <th>Spermine</th>\n",
+       "      <th>Spermine.1</th>\n",
+       "      <th>Spermidine</th>\n",
+       "      <th>N-Formyl-L-Methionine</th>\n",
+       "      <th>Indole-3-acetic acid</th>\n",
+       "      <th>Indole-3-acetic acid.1</th>\n",
+       "      <th>N-Acetyl-D-glucosamine</th>\n",
+       "      <th>N-Acetyl-D-glucosamine.1</th>\n",
+       "      <th>N-Acetyl-D-glucosamine.2</th>\n",
+       "      <th>...</th>\n",
+       "      <th>L-Valine.10</th>\n",
+       "      <th>L-Valine.11</th>\n",
+       "      <th>L-Asparagine.12</th>\n",
+       "      <th>Pyrene.5</th>\n",
+       "      <th>Pyrene.6</th>\n",
+       "      <th>Pyrene.7</th>\n",
+       "      <th>Anthracene.1</th>\n",
+       "      <th>Anthracene.2</th>\n",
+       "      <th>Anthracene.3</th>\n",
+       "      <th>Anthracene.4</th>\n",
+       "    </tr>\n",
+       "  </thead>\n",
+       "  <tbody>\n",
+       "    <tr>\n",
+       "      <th>0</th>\n",
+       "      <td>0.055132</td>\n",
+       "      <td>-0.193670</td>\n",
+       "      <td>-0.192471</td>\n",
+       "      <td>-0.158782</td>\n",
+       "      <td>0.345823</td>\n",
+       "      <td>0.183409</td>\n",
+       "      <td>0.136151</td>\n",
+       "      <td>0.028029</td>\n",
+       "      <td>0.024352</td>\n",
+       "      <td>0.021363</td>\n",
+       "      <td>...</td>\n",
+       "      <td>0.118893</td>\n",
+       "      <td>0.106765</td>\n",
+       "      <td>0.287579</td>\n",
+       "      <td>0.446005</td>\n",
+       "      <td>0.445787</td>\n",
+       "      <td>0.445787</td>\n",
+       "      <td>0.520587</td>\n",
+       "      <td>0.522934</td>\n",
+       "      <td>0.519045</td>\n",
+       "      <td>0.519400</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>1</th>\n",
+       "      <td>0.040264</td>\n",
+       "      <td>0.004480</td>\n",
+       "      <td>0.006009</td>\n",
+       "      <td>0.015572</td>\n",
+       "      <td>0.005429</td>\n",
+       "      <td>0.019701</td>\n",
+       "      <td>-0.004669</td>\n",
+       "      <td>0.052705</td>\n",
+       "      <td>0.049193</td>\n",
+       "      <td>0.052515</td>\n",
+       "      <td>...</td>\n",
+       "      <td>0.001075</td>\n",
+       "      <td>-0.000667</td>\n",
+       "      <td>-0.003480</td>\n",
+       "      <td>-0.004765</td>\n",
+       "      <td>-0.005302</td>\n",
+       "      <td>-0.005302</td>\n",
+       "      <td>-0.023605</td>\n",
+       "      <td>0.002114</td>\n",
+       "      <td>0.000329</td>\n",
+       "      <td>0.000220</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>2</th>\n",
+       "      <td>-0.243919</td>\n",
+       "      <td>0.452616</td>\n",
+       "      <td>0.452230</td>\n",
+       "      <td>0.389119</td>\n",
+       "      <td>-0.228511</td>\n",
+       "      <td>-0.099166</td>\n",
+       "      <td>-0.116724</td>\n",
+       "      <td>-0.006005</td>\n",
+       "      <td>-0.006790</td>\n",
+       "      <td>0.009915</td>\n",
+       "      <td>...</td>\n",
+       "      <td>-0.371256</td>\n",
+       "      <td>-0.323713</td>\n",
+       "      <td>-0.186779</td>\n",
+       "      <td>0.063433</td>\n",
+       "      <td>0.063580</td>\n",
+       "      <td>0.063580</td>\n",
+       "      <td>0.224672</td>\n",
+       "      <td>0.201298</td>\n",
+       "      <td>0.201356</td>\n",
+       "      <td>0.200905</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>3</th>\n",
+       "      <td>0.044400</td>\n",
+       "      <td>0.432583</td>\n",
+       "      <td>0.431999</td>\n",
+       "      <td>0.438530</td>\n",
+       "      <td>0.386104</td>\n",
+       "      <td>0.829133</td>\n",
+       "      <td>0.722940</td>\n",
+       "      <td>0.223304</td>\n",
+       "      <td>0.211854</td>\n",
+       "      <td>0.223674</td>\n",
+       "      <td>...</td>\n",
+       "      <td>0.084759</td>\n",
+       "      <td>0.160962</td>\n",
+       "      <td>0.526005</td>\n",
+       "      <td>0.435560</td>\n",
+       "      <td>0.437032</td>\n",
+       "      <td>0.437032</td>\n",
+       "      <td>0.569034</td>\n",
+       "      <td>0.486343</td>\n",
+       "      <td>0.483668</td>\n",
+       "      <td>0.482976</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>4</th>\n",
+       "      <td>-0.016782</td>\n",
+       "      <td>-0.023511</td>\n",
+       "      <td>-0.023564</td>\n",
+       "      <td>-0.022483</td>\n",
+       "      <td>-0.048616</td>\n",
+       "      <td>-0.068970</td>\n",
+       "      <td>-0.095380</td>\n",
+       "      <td>-0.243234</td>\n",
+       "      <td>-0.237421</td>\n",
+       "      <td>-0.240412</td>\n",
+       "      <td>...</td>\n",
+       "      <td>-0.013173</td>\n",
+       "      <td>-0.031125</td>\n",
+       "      <td>-0.045651</td>\n",
+       "      <td>-0.022121</td>\n",
+       "      <td>-0.021799</td>\n",
+       "      <td>-0.021799</td>\n",
+       "      <td>-0.097070</td>\n",
+       "      <td>-0.043298</td>\n",
+       "      <td>-0.044704</td>\n",
+       "      <td>-0.044299</td>\n",
+       "    </tr>\n",
+       "  </tbody>\n",
+       "</table>\n",
+       "<p>5 rows × 296 columns</p>\n",
+       "</div>"
+      ],
+      "text/plain": [
+       "   Succinic acid  Spermine  Spermine.1  Spermidine  N-Formyl-L-Methionine  \\\n",
+       "0       0.055132 -0.193670   -0.192471   -0.158782               0.345823   \n",
+       "1       0.040264  0.004480    0.006009    0.015572               0.005429   \n",
+       "2      -0.243919  0.452616    0.452230    0.389119              -0.228511   \n",
+       "3       0.044400  0.432583    0.431999    0.438530               0.386104   \n",
+       "4      -0.016782 -0.023511   -0.023564   -0.022483              -0.048616   \n",
+       "\n",
+       "   Indole-3-acetic acid  Indole-3-acetic acid.1  N-Acetyl-D-glucosamine  \\\n",
+       "0              0.183409                0.136151                0.028029   \n",
+       "1              0.019701               -0.004669                0.052705   \n",
+       "2             -0.099166               -0.116724               -0.006005   \n",
+       "3              0.829133                0.722940                0.223304   \n",
+       "4             -0.068970               -0.095380               -0.243234   \n",
+       "\n",
+       "   N-Acetyl-D-glucosamine.1  N-Acetyl-D-glucosamine.2  ...  L-Valine.10  \\\n",
+       "0                  0.024352                  0.021363  ...     0.118893   \n",
+       "1                  0.049193                  0.052515  ...     0.001075   \n",
+       "2                 -0.006790                  0.009915  ...    -0.371256   \n",
+       "3                  0.211854                  0.223674  ...     0.084759   \n",
+       "4                 -0.237421                 -0.240412  ...    -0.013173   \n",
+       "\n",
+       "   L-Valine.11  L-Asparagine.12  Pyrene.5  Pyrene.6  Pyrene.7  Anthracene.1  \\\n",
+       "0     0.106765         0.287579  0.446005  0.445787  0.445787      0.520587   \n",
+       "1    -0.000667        -0.003480 -0.004765 -0.005302 -0.005302     -0.023605   \n",
+       "2    -0.323713        -0.186779  0.063433  0.063580  0.063580      0.224672   \n",
+       "3     0.160962         0.526005  0.435560  0.437032  0.437032      0.569034   \n",
+       "4    -0.031125        -0.045651 -0.022121 -0.021799 -0.021799     -0.097070   \n",
+       "\n",
+       "   Anthracene.2  Anthracene.3  Anthracene.4  \n",
+       "0      0.522934      0.519045      0.519400  \n",
+       "1      0.002114      0.000329      0.000220  \n",
+       "2      0.201298      0.201356      0.200905  \n",
+       "3      0.486343      0.483668      0.482976  \n",
+       "4     -0.043298     -0.044704     -0.044299  \n",
+       "\n",
+       "[5 rows x 296 columns]"
+      ]
+     },
+     "execution_count": 45,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "mass_spec_encoder_generated_embeddings.head()"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 35,
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/html": [
+       "<div>\n",
+       "<style scoped>\n",
+       "    .dataframe tbody tr th:only-of-type {\n",
+       "        vertical-align: middle;\n",
+       "    }\n",
+       "\n",
+       "    .dataframe tbody tr th {\n",
+       "        vertical-align: top;\n",
+       "    }\n",
+       "\n",
+       "    .dataframe thead th {\n",
+       "        text-align: right;\n",
+       "    }\n",
+       "</style>\n",
+       "<table border=\"1\" class=\"dataframe\">\n",
+       "  <thead>\n",
+       "    <tr style=\"text-align: right;\">\n",
+       "      <th></th>\n",
+       "      <th>Name</th>\n",
+       "      <th>SMILES</th>\n",
+       "      <th>embedding</th>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>Unnamed: 0</th>\n",
+       "      <th></th>\n",
+       "      <th></th>\n",
+       "      <th></th>\n",
+       "    </tr>\n",
+       "  </thead>\n",
+       "  <tbody>\n",
+       "    <tr>\n",
+       "      <th>BKG</th>\n",
+       "      <td>background</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>DEM</th>\n",
+       "      <td>Diethyl Malonate</td>\n",
+       "      <td>CCOC(=O)CC(=O)OCC</td>\n",
+       "      <td>[0.3809721, 0.0005454041, 0.25539744, -0.24272...</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>DEB</th>\n",
+       "      <td>1,2,3,4-Diepoxybutane</td>\n",
+       "      <td>C1C(O1)C2CO2</td>\n",
+       "      <td>[0.06318794, 0.009022224, 0.42160064, 0.195722...</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>MES</th>\n",
+       "      <td>2-(N-morpholino)ethanesulfonic acid</td>\n",
+       "      <td>C1COCCN1CCS(=O)(=O)O</td>\n",
+       "      <td>[-0.32520828, 0.009838344, -0.15108332, 0.2845...</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>DMMP</th>\n",
+       "      <td>Dimethyl methylphosphonate</td>\n",
+       "      <td>COP(=O)(C)OC</td>\n",
+       "      <td>[0.12106811, 0.00294244, -0.14450458, 0.072665...</td>\n",
+       "    </tr>\n",
+       "  </tbody>\n",
+       "</table>\n",
+       "</div>"
+      ],
+      "text/plain": [
+       "                                           Name                SMILES  \\\n",
+       "Unnamed: 0                                                              \n",
+       "BKG                                  background                   NaN   \n",
+       "DEM                            Diethyl Malonate     CCOC(=O)CC(=O)OCC   \n",
+       "DEB                       1,2,3,4-Diepoxybutane          C1C(O1)C2CO2   \n",
+       "MES         2-(N-morpholino)ethanesulfonic acid  C1COCCN1CCS(=O)(=O)O   \n",
+       "DMMP                 Dimethyl methylphosphonate          COP(=O)(C)OC   \n",
+       "\n",
+       "                                                    embedding  \n",
+       "Unnamed: 0                                                     \n",
+       "BKG                                                       NaN  \n",
+       "DEM         [0.3809721, 0.0005454041, 0.25539744, -0.24272...  \n",
+       "DEB         [0.06318794, 0.009022224, 0.42160064, 0.195722...  \n",
+       "MES         [-0.32520828, 0.009838344, -0.15108332, 0.2845...  \n",
+       "DMMP        [0.12106811, 0.00294244, -0.14450458, 0.072665...  "
+      ]
+     },
+     "execution_count": 35,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "# set the df index to be the chemical abbreviations in col 'Unnamed: 0'\n",
+    "name_smiles_embedding_df.set_index('Unnamed: 0', inplace=True)\n",
+    "name_smiles_embedding_df.head()"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 36,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "embedding_floats = []\n",
+    "for chem_name in name_smiles_embedding_df.index:\n",
+    "    if chem_name == 'BKG':\n",
+    "        embedding_floats.append(None)\n",
+    "    else:\n",
+    "        embedding_float = name_smiles_embedding_df['embedding'][chem_name].split('[')[1]\n",
+    "        embedding_float = embedding_float.split(']')[0]\n",
+    "        embedding_float = [np.float32(num) for num in embedding_float.split(',')]\n",
+    "        embedding_floats.append(embedding_float)\n",
+    "\n",
+    "name_smiles_embedding_df['Embedding Floats'] = embedding_floats"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 44,
+   "metadata": {},
+   "outputs": [
+    {
+     "ename": "KeyError",
+     "evalue": "'Label'",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
+      "File \u001b[0;32m~/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
+      "File \u001b[0;32m~/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
+      "File \u001b[0;32m~/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
+      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
+      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
+      "\u001b[0;31mKeyError\u001b[0m: 'Label'",
+      "\nThe above exception was the direct cause of the following exception:\n",
+      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
+      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# filtering out chems with < 5 embeddings\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mass_spec_chem_counts \u001b[38;5;241m=\u001b[39m Counter(\u001b[43mmass_spec_encoder_generated_embeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      3\u001b[0m chems_above_5 \u001b[38;5;241m=\u001b[39m [key \u001b[38;5;28;01mfor\u001b[39;00m key, count \u001b[38;5;129;01min\u001b[39;00m mass_spec_chem_counts\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m      4\u001b[0m filtered_mass_spec_embeddings \u001b[38;5;241m=\u001b[39m mass_spec_embeddings[chems_above_5]\n",
+      "File \u001b[0;32m~/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
+      "File \u001b[0;32m~/ChemicalDataGeneration/chem_data_gen/lib/python3.8/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
+      "\u001b[0;31mKeyError\u001b[0m: 'Label'"
+     ]
+    }
+   ],
+   "source": [
+    "# filtering out chems with < 5 embeddings\n",
+    "mass_spec_chem_counts = Counter(mass_spec_encoder_generated_embeddings['Label'])\n",
+    "chems_above_5 = [key for key, count in mass_spec_chem_counts.items() if count >= 5]\n",
+    "filtered_mass_spec_embeddings = mass_spec_embeddings[chems_above_5]\n",
+    "filtered_mass_spec_encoder_generated_embeddings = mass_spec_encoder_generated_embeddings[mass_spec_encoder_generated_embeddings['Label'].isin(chems_above_5)]\n",
+    "\n",
+    "# Combine embeddings for IMS simulants and mass spec chems to use for plotting pca\n",
+    "ims_embeddings = pd.DataFrame([emb for emb in name_smiles_embedding_df['Embedding Floats']][1:]).T\n",
+    "cols = name_smiles_embedding_df.index[1:]\n",
+    "ims_embeddings.columns = cols\n",
+    "all_true_embeddings = pd.concat([ims_embeddings, filtered_mass_spec_embeddings], axis=1)\n",
+    "all_true_embeddings.head()"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Setting up GPU:\n",
+    "---"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 38,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Selected GPU ID: 0\n",
+      "  Name: NVIDIA GeForce RTX 4090\n",
+      "  Memory Free: 22148.0 MB\n",
+      "  Memory Used: 2069.0 MB\n",
+      "  GPU Load: 90.00%\n",
+      "Current device ID:  cuda:0\n",
+      "PyTorch current device ID: 0\n",
+      "PyTorch current device name: NVIDIA GeForce RTX 4090\n"
+     ]
+    }
+   ],
+   "source": [
+    "if torch.cuda.is_available():\n",
+    "    # Get the list of GPUs\n",
     "    gpus = GPUtil.getGPUs()\n",
     "\n",
     "    # Find the GPU with the most free memory\n",
@@ -240,7 +720,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 20,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -262,7 +742,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 21,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -285,7 +765,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 10,
+   "execution_count": 22,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -297,7 +777,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 11,
+   "execution_count": 23,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -341,7 +821,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 12,
+   "execution_count": 24,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -406,7 +886,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 13,
+   "execution_count": 25,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -441,7 +921,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 14,
+   "execution_count": 26,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -578,7 +1058,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 15,
+   "execution_count": 27,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -611,7 +1091,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 16,
+   "execution_count": 28,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -645,7 +1125,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 17,
+   "execution_count": 29,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -792,40 +1272,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 18,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "# Encoder for truncated dataset\n",
-    "class TruncatedEncoder(nn.Module):\n",
-    "  def __init__(self):\n",
-    "    super().__init__()\n",
-    "    self.encoder = nn.Sequential(\n",
-    "      nn.Linear(1032,968),\n",
-    "      nn.LeakyReLU(inplace=True),\n",
-    "      nn.Linear(968,904),\n",
-    "      nn.LeakyReLU(inplace=True),\n",
-    "      nn.Linear(904, 840),\n",
-    "      nn.LeakyReLU(inplace=True),\n",
-    "      nn.Linear(840, 776),\n",
-    "      nn.LeakyReLU(inplace=True),\n",
-    "      nn.Linear(776, 712),\n",
-    "      nn.LeakyReLU(inplace=True),\n",
-    "      nn.Linear(712, 648),\n",
-    "      nn.LeakyReLU(inplace=True),\n",
-    "      nn.Linear(648, 584),\n",
-    "      nn.LeakyReLU(inplace=True),\n",
-    "      nn.Linear(584, 512),\n",
-    "    )\n",
-    "\n",
-    "  def forward(self, x):\n",
-    "    x = self.encoder(x)\n",
-    "    return x"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 19,
+   "execution_count": 32,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -839,262 +1286,12 @@
     "\n",
     "    # create tensors of spectra, true embeddings, and chemical name encodings for train and val\n",
     "    chem_labels = list(spectra_dataset['Label'])\n",
-    "    embeddings_tensor = torch.Tensor([embedding_df['Embedding Floats'][chem_name] for chem_name in chem_labels]).to(device)\n",
-    "    spectra_tensor = torch.Tensor(spectra.values).to(device)\n",
-    "    chem_encodings_tensor = torch.Tensor(chem_encodings.values).to(device)\n",
-    "    spectra_indices_tensor = torch.Tensor(spectra_dataset['index'].to_numpy()).to(device)\n",
-    "\n",
-    "    return embeddings_tensor, spectra_tensor, chem_encodings_tensor, spectra_indices_tensor"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 3,
-   "metadata": {},
-   "outputs": [
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "/tmp/ipykernel_224248/2621477981.py:5: DtypeWarning: Columns (1677) have mixed types. Specify dtype option on import or set low_memory=False.\n",
-      "  val_carls = pd.read_csv(file_path)\n",
-      "/tmp/ipykernel_224248/2621477981.py:7: DtypeWarning: Columns (1677) have mixed types. Specify dtype option on import or set low_memory=False.\n",
-      "  test_carls = pd.read_csv(file_path)\n"
-     ]
-    }
-   ],
-   "source": [
-    "file_path = '/mnt/usb/cmdunham/preprocessed_ims_data/train_carls.csv'\n",
-    "train_carls = pd.read_csv(file_path)\n",
-    "file_path = '/mnt/usb/cmdunham/preprocessed_ims_data/val_carls.csv'\n",
-    "val_carls = pd.read_csv(file_path)\n",
-    "file_path='/mnt/usb/cmdunham/preprocessed_ims_data/test_carls.csv'\n",
-    "test_carls = pd.read_csv(file_path)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 8,
-   "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/html": [
-       "<div>\n",
-       "<style scoped>\n",
-       "    .dataframe tbody tr th:only-of-type {\n",
-       "        vertical-align: middle;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe tbody tr th {\n",
-       "        vertical-align: top;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe thead th {\n",
-       "        text-align: right;\n",
-       "    }\n",
-       "</style>\n",
-       "<table border=\"1\" class=\"dataframe\">\n",
-       "  <thead>\n",
-       "    <tr style=\"text-align: right;\">\n",
-       "      <th></th>\n",
-       "      <th>index</th>\n",
-       "      <th>p_184</th>\n",
-       "      <th>p_185</th>\n",
-       "      <th>p_186</th>\n",
-       "      <th>p_187</th>\n",
-       "      <th>p_188</th>\n",
-       "      <th>p_189</th>\n",
-       "      <th>p_190</th>\n",
-       "      <th>p_191</th>\n",
-       "      <th>p_192</th>\n",
-       "      <th>...</th>\n",
-       "      <th>n_1021</th>\n",
-       "      <th>Label</th>\n",
-       "      <th>DEB</th>\n",
-       "      <th>DEM</th>\n",
-       "      <th>DMMP</th>\n",
-       "      <th>DPM</th>\n",
-       "      <th>DtBP</th>\n",
-       "      <th>JP8</th>\n",
-       "      <th>MES</th>\n",
-       "      <th>TEPO</th>\n",
-       "    </tr>\n",
-       "  </thead>\n",
-       "  <tbody>\n",
-       "    <tr>\n",
-       "      <th>0</th>\n",
-       "      <td>1297539</td>\n",
-       "      <td>-12.0</td>\n",
-       "      <td>-14.0</td>\n",
-       "      <td>-16.0</td>\n",
-       "      <td>-20.0</td>\n",
-       "      <td>-21.0</td>\n",
-       "      <td>-22.0</td>\n",
-       "      <td>-22.0</td>\n",
-       "      <td>-24.0</td>\n",
-       "      <td>-25.0</td>\n",
-       "      <td>...</td>\n",
-       "      <td>-8.0</td>\n",
-       "      <td>DtBP</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>1.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>1</th>\n",
-       "      <td>1297539</td>\n",
-       "      <td>-12.0</td>\n",
-       "      <td>-10.0</td>\n",
-       "      <td>-7.0</td>\n",
-       "      <td>-4.0</td>\n",
-       "      <td>1.0</td>\n",
-       "      <td>3.0</td>\n",
-       "      <td>7.0</td>\n",
-       "      <td>6.0</td>\n",
-       "      <td>8.0</td>\n",
-       "      <td>...</td>\n",
-       "      <td>15.0</td>\n",
-       "      <td>DMMP</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>1.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>2</th>\n",
-       "      <td>1344903</td>\n",
-       "      <td>2.0</td>\n",
-       "      <td>2.0</td>\n",
-       "      <td>2.0</td>\n",
-       "      <td>1.0</td>\n",
-       "      <td>2.0</td>\n",
-       "      <td>2.0</td>\n",
-       "      <td>1.0</td>\n",
-       "      <td>1.0</td>\n",
-       "      <td>-2.0</td>\n",
-       "      <td>...</td>\n",
-       "      <td>-7.0</td>\n",
-       "      <td>TEPO</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>1.0</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>3</th>\n",
-       "      <td>1344903</td>\n",
-       "      <td>2.0</td>\n",
-       "      <td>6.0</td>\n",
-       "      <td>11.0</td>\n",
-       "      <td>17.0</td>\n",
-       "      <td>24.0</td>\n",
-       "      <td>27.0</td>\n",
-       "      <td>30.0</td>\n",
-       "      <td>31.0</td>\n",
-       "      <td>31.0</td>\n",
-       "      <td>...</td>\n",
-       "      <td>16.0</td>\n",
-       "      <td>DtBP</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>1.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>4</th>\n",
-       "      <td>1221071</td>\n",
-       "      <td>10.0</td>\n",
-       "      <td>12.0</td>\n",
-       "      <td>15.0</td>\n",
-       "      <td>14.0</td>\n",
-       "      <td>17.0</td>\n",
-       "      <td>19.0</td>\n",
-       "      <td>22.0</td>\n",
-       "      <td>23.0</td>\n",
-       "      <td>26.0</td>\n",
-       "      <td>...</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>TEPO</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>0.0</td>\n",
-       "      <td>1.0</td>\n",
-       "    </tr>\n",
-       "  </tbody>\n",
-       "</table>\n",
-       "<p>5 rows × 1686 columns</p>\n",
-       "</div>"
-      ],
-      "text/plain": [
-       "     index  p_184  p_185  p_186  p_187  p_188  p_189  p_190  p_191  p_192  \\\n",
-       "0  1297539  -12.0  -14.0  -16.0  -20.0  -21.0  -22.0  -22.0  -24.0  -25.0   \n",
-       "1  1297539  -12.0  -10.0   -7.0   -4.0    1.0    3.0    7.0    6.0    8.0   \n",
-       "2  1344903    2.0    2.0    2.0    1.0    2.0    2.0    1.0    1.0   -2.0   \n",
-       "3  1344903    2.0    6.0   11.0   17.0   24.0   27.0   30.0   31.0   31.0   \n",
-       "4  1221071   10.0   12.0   15.0   14.0   17.0   19.0   22.0   23.0   26.0   \n",
-       "\n",
-       "   ...  n_1021  Label  DEB  DEM  DMMP  DPM  DtBP  JP8  MES  TEPO  \n",
-       "0  ...    -8.0   DtBP  0.0  0.0   0.0  0.0   1.0  0.0  0.0   0.0  \n",
-       "1  ...    15.0   DMMP  0.0  0.0   1.0  0.0   0.0  0.0  0.0   0.0  \n",
-       "2  ...    -7.0   TEPO  0.0  0.0   0.0  0.0   0.0  0.0  0.0   1.0  \n",
-       "3  ...    16.0   DtBP  0.0  0.0   0.0  0.0   1.0  0.0  0.0   0.0  \n",
-       "4  ...     0.0   TEPO  0.0  0.0   0.0  0.0   0.0  0.0  0.0   1.0  \n",
-       "\n",
-       "[5 rows x 1686 columns]"
-      ]
-     },
-     "execution_count": 8,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "train_carls.head()"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 6,
-   "metadata": {},
-   "outputs": [
-    {
-     "ename": "NameError",
-     "evalue": "name 'create_dataset_tensors' is not defined",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
-      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# train_embeddings_tensor, train_carl_tensor, train_chem_encodings_tensor, train_carl_indices_tensor = create_dataset_tensors(train_carls, name_smiles_embedding_df, device, carl=True)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m val_embeddings_tensor, val_carl_tensor, val_chem_encodings_tensor, val_carl_indices_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dataset_tensors\u001b[49m(val_carls, name_smiles_embedding_df, device, carl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m test_embeddings_tensor, test_carl_tensor, test_chem_encodings_tensor, test_carl_indices_tensor \u001b[38;5;241m=\u001b[39m create_dataset_tensors(test_carls, name_smiles_embedding_df, device, carl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
-      "\u001b[0;31mNameError\u001b[0m: name 'create_dataset_tensors' is not defined"
-     ]
-    }
-   ],
-   "source": [
-    "train_embeddings_tensor, train_carl_tensor, train_chem_encodings_tensor, train_carl_indices_tensor = create_dataset_tensors(train_carls, name_smiles_embedding_df, device, carl=True)\n",
-    "val_embeddings_tensor, val_carl_tensor, val_chem_encodings_tensor, val_carl_indices_tensor = create_dataset_tensors(val_carls, name_smiles_embedding_df, device, carl=True)\n",
-    "test_embeddings_tensor, test_carl_tensor, test_chem_encodings_tensor, test_carl_indices_tensor = create_dataset_tensors(test_carls, name_smiles_embedding_df, device, carl=True)"
+    "    embeddings_tensor = torch.Tensor([embedding_df['Embedding Floats'][chem_name] for chem_name in chem_labels]).to(device)\n",
+    "    spectra_tensor = torch.Tensor(spectra.values).to(device)\n",
+    "    chem_encodings_tensor = torch.Tensor(chem_encodings.values).to(device)\n",
+    "    spectra_indices_tensor = torch.Tensor(spectra_dataset['index'].to_numpy()).to(device)\n",
+    "\n",
+    "    return embeddings_tensor, spectra_tensor, chem_encodings_tensor, spectra_indices_tensor"
    ]
   },
   {
@@ -1107,7 +1304,18 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 40,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "train_embeddings_tensor, train_carl_tensor, train_chem_encodings_tensor, train_carl_indices_tensor = create_dataset_tensors(train_carls, name_smiles_embedding_df, device, carl=True)\n",
+    "val_embeddings_tensor, val_carl_tensor, val_chem_encodings_tensor, val_carl_indices_tensor = create_dataset_tensors(val_carls, name_smiles_embedding_df, device, carl=True)\n",
+    "test_embeddings_tensor, test_carl_tensor, test_chem_encodings_tensor, test_carl_indices_tensor = create_dataset_tensors(test_carls, name_smiles_embedding_df, device, carl=True)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 41,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -1118,14 +1326,27 @@
     "    'threads':1,\n",
     "}\n",
     "\n",
-    "os.environ['WANDB_NOTEBOOK_NAME'] = '/home/cmdunham/ChemicalDataGeneration/models/ims_encoder.ipynb'"
+    "os.environ['WANDB_NOTEBOOK_NAME'] = '/home/cmdunham/ChemicalDataGeneration/models/carl_encoder.ipynb'"
    ]
   },
   {
-   "cell_type": "markdown",
+   "cell_type": "code",
+   "execution_count": 43,
    "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "Index(['DEB', 'DEM', 'DMMP', 'DPM', 'DtBP', 'JP8', 'MES', 'TEPO'], dtype='object')"
+      ]
+     },
+     "execution_count": 43,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
    "source": [
-    "Most successful run so far trained for 10 epochs at .0001 before training at .00001 for 100 epochs. Clusters were very tight, possibly too tight?"
+    "train_carls.columns[-8:]"
    ]
   },
   {
@@ -1134,115 +1355,37 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "# set var deciding if embedding pca plot for this run is saved to wandb\n",
-    "save_emb_pca_to_wandb = True\n",
+    "wandb_kwargs = {\n",
+    "    'architecture':'ims_encoder',\n",
+    "    'optimizer':'AdamW',\n",
+    "    'loss':'MSELoss',\n",
+    "    'dataset':'IMS',\n",
+    "    'target_embedding':'ChemNet'\n",
+    "}\n",
     "\n",
-    "# Last 8 cols of the df are the chem names\n",
     "sorted_chem_names = list(train_carls.columns[-8:])\n",
     "\n",
-    "model_config = {\n",
-    "  'batch_size':[128],\n",
-    "  'epochs': [100],\n",
-    "  'learning_rate':[.00001]\n",
-    "  }\n",
-    "\n",
-    "# loss to compare for each model. Starting at something high so it will be replaced by first model's loss \n",
-    "lowest_loss = 100\n",
-    "\n",
-    "# model_config = {\n",
-    "#     'batch_size': [128],\n",
-    "#     'epochs': [10],\n",
-    "#     'learning_rate': [.00001]\n",
-    "# }\n",
-    "\n",
-    "keys = model_config.keys()\n",
-    "values = model_config.values()\n",
-    "\n",
-    "# Generate all parameter combinations from model_config using itertools.product\n",
-    "combinations = itertools.product(*values)\n",
-    "\n",
-    "# Iterate through each parameter combination and run model \n",
-    "for combo in combinations:\n",
-    "  combo = dict(zip(keys, combo))\n",
-    "\n",
-    "  train_dataset = DataLoader(TensorDataset(train_carl_tensor, train_chem_encodings_tensor, train_embeddings_tensor, train_carl_indices_tensor), batch_size=combo['batch_size'], shuffle=True)\n",
-    "  val_dataset = DataLoader(TensorDataset(val_carl_tensor, val_chem_encodings_tensor, val_embeddings_tensor, val_carl_indices_tensor), batch_size=combo['batch_size'], shuffle=False)\n",
-    "  encoder = Encoder().to(device)\n",
-    "\n",
-    "  encoder_optimizer = torch.optim.AdamW(encoder.parameters(), lr = combo['learning_rate'])\n",
-    "  encoder_criterion = nn.MSELoss()\n",
-    "\n",
-    "  wandb_kwargs = {\n",
-    "    'learning_rate': combo['learning_rate'],\n",
-    "    'epochs': combo['epochs'],\n",
-    "    'batch_size': combo['batch_size'],\n",
-    "    'model_architecture': 'carl_encoder',\n",
-    "    'optimizer':'AdamW',\n",
-    "    'loss': 'MSELoss'\n",
+    "model_hyperparams = {\n",
+    "  'batch_size':[64, 32],\n",
+    "  'epochs': [500],\n",
+    "  'learning_rate':[.0000001]\n",
     "  }\n",
     "\n",
-    "  run_with_wandb(config, **wandb_kwargs)\n",
-    "\n",
-    "  print('--------------------------')\n",
-    "  print('--------------------------')\n",
-    "  print('New run with hyperparameters:')\n",
-    "  for key in combo:\n",
-    "    print(key, ' : ', combo[key])\n",
-    "\n",
-    "  for epoch in range(combo['epochs']):\n",
-    "    # Set model to training mode\n",
-    "    encoder.train(True)\n",
-    "\n",
-    "    # do a pass over the data\n",
-    "    # at last epoch get predicted embeddings and chem names\n",
-    "    if (epoch + 1) == combo['epochs']:\n",
-    "      average_loss, predicted_embeddings, output_name_encodings = train_one_epoch(\n",
-    "        train_dataset, device, encoder, encoder_criterion, encoder_optimizer, epoch, combo\n",
-    "        )\n",
-    "    else:\n",
-    "      average_loss = train_one_epoch(\n",
-    "        train_dataset, device, encoder, encoder_criterion, encoder_optimizer, epoch, combo\n",
-    "        )\n",
-    "\n",
-    "    epoch_val_loss = 0  \n",
-    "    # evaluate model on validation data\n",
-    "    encoder.eval() # Set model to evaluation mode\n",
-    "    with torch.no_grad():\n",
-    "      for val_batch, val_name_encodings, val_true_embeddings, val_spectra_indices in val_dataset:\n",
-    "        val_batch = val_batch.to(device)\n",
-    "        val_name_encodings = val_name_encodings.to(device)\n",
-    "        val_true_embeddings = val_true_embeddings.to(device)\n",
-    "\n",
-    "        val_batch_predicted_embeddings = encoder(val_batch)\n",
-    "\n",
-    "        val_loss = encoder_criterion(val_batch_predicted_embeddings, val_true_embeddings)\n",
-    "        # accumulate epoch validation loss\n",
-    "        epoch_val_loss += val_loss.item()\n",
-    "\n",
-    "    # divide by number of batches to calculate average loss\n",
-    "    val_average_loss = epoch_val_loss/len(val_dataset)\n",
-    "\n",
-    "    # log losses to wandb\n",
-    "    wandb.log({\"Encoder Training Loss\": average_loss, \"Encoder Validation Loss\": val_average_loss})\n",
-    "    # wandb.log({\"Encoder Training Loss\": average_loss})\n",
-    "\n",
-    "    if (epoch + 1) % 10 == 0:\n",
-    "      print('Epoch[{}/{}]:'.format(epoch+1, combo['epochs']))\n",
-    "      print(f'   Training loss: {average_loss}')\n",
-    "      print(f'   Validation loss: {val_average_loss}')\n",
-    "      print('-------------------------------------------')\n",
-    "\n",
-    "  if save_emb_pca_to_wandb:\n",
-    "    true_embeddings, predicted_embeddings_flattened, chem_names = preds_to_emb_pca_plot(predicted_embeddings, output_name_encodings, sorted_chem_names, name_smiles_embedding_df)\n",
+    "encoder_path = '../models/ims_to_chemnet_encoder.pth'\n",
     "\n",
-    "  if average_loss < lowest_loss:\n",
-    "    best_hyperparams = combo\n",
+    "train_data = TensorDataset(train_carl_tensor, train_chem_encodings_tensor, train_embeddings_tensor, train_carl_indices_tensor)\n",
+    "val_data = TensorDataset(val_carl_tensor, val_chem_encodings_tensor, val_embeddings_tensor, val_carl_indices_tensor)\n",
+    "test_data = TensorDataset(test_carl_tensor, test_chem_encodings_tensor, test_embeddings_tensor, test_carl_indices_tensor)\n",
     "\n",
-    "  wandb.finish()\n",
+    "# encoder = Encoder().to(device)\n",
     "\n",
-    "print('Hyperparameters for best model: ')\n",
-    "for key in best_hyperparams:\n",
-    "  print('   ', key, ' : ', best_hyperparams[key])"
+    "best_hyperparams = train_model(\n",
+    "    'Encoder', train_data, val_data, test_data, \n",
+    "    device, config, wandb_kwargs, \n",
+    "    all_true_embeddings, name_smiles_embedding_df, model_hyperparams, \n",
+    "    sorted_chem_names, encoder_path, save_emb_pca_to_wandb=True, \n",
+    "    show_wandb_run_name=True\n",
+    "    )"
    ]
   },
   {
@@ -1405,6 +1548,131 @@
     "# test_preds_df.to_csv(file_path, index=False)"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "# Unused Code:\n",
+    "---"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# set var deciding if embedding pca plot for this run is saved to wandb\n",
+    "save_emb_pca_to_wandb = True\n",
+    "\n",
+    "# Last 8 cols of the df are the chem names\n",
+    "sorted_chem_names = list(train_carls.columns[-8:])\n",
+    "\n",
+    "model_config = {\n",
+    "  'batch_size':[128],\n",
+    "  'epochs': [100],\n",
+    "  'learning_rate':[.00001]\n",
+    "  }\n",
+    "\n",
+    "# loss to compare for each model. Starting at something high so it will be replaced by first model's loss \n",
+    "lowest_loss = 100\n",
+    "\n",
+    "# model_config = {\n",
+    "#     'batch_size': [128],\n",
+    "#     'epochs': [10],\n",
+    "#     'learning_rate': [.00001]\n",
+    "# }\n",
+    "\n",
+    "keys = model_config.keys()\n",
+    "values = model_config.values()\n",
+    "\n",
+    "# Generate all parameter combinations from model_config using itertools.product\n",
+    "combinations = itertools.product(*values)\n",
+    "\n",
+    "# Iterate through each parameter combination and run model \n",
+    "for combo in combinations:\n",
+    "  combo = dict(zip(keys, combo))\n",
+    "\n",
+    "  train_dataset = DataLoader(TensorDataset(train_carl_tensor, train_chem_encodings_tensor, train_embeddings_tensor, train_carl_indices_tensor), batch_size=combo['batch_size'], shuffle=True)\n",
+    "  val_dataset = DataLoader(TensorDataset(val_carl_tensor, val_chem_encodings_tensor, val_embeddings_tensor, val_carl_indices_tensor), batch_size=combo['batch_size'], shuffle=False)\n",
+    "  encoder = Encoder().to(device)\n",
+    "\n",
+    "  encoder_optimizer = torch.optim.AdamW(encoder.parameters(), lr = combo['learning_rate'])\n",
+    "  encoder_criterion = nn.MSELoss()\n",
+    "\n",
+    "  wandb_kwargs = {\n",
+    "    'learning_rate': combo['learning_rate'],\n",
+    "    'epochs': combo['epochs'],\n",
+    "    'batch_size': combo['batch_size'],\n",
+    "    'model_architecture': 'carl_encoder',\n",
+    "    'optimizer':'AdamW',\n",
+    "    'loss': 'MSELoss'\n",
+    "  }\n",
+    "\n",
+    "  run_with_wandb(config, **wandb_kwargs)\n",
+    "\n",
+    "  print('--------------------------')\n",
+    "  print('--------------------------')\n",
+    "  print('New run with hyperparameters:')\n",
+    "  for key in combo:\n",
+    "    print(key, ' : ', combo[key])\n",
+    "\n",
+    "  for epoch in range(combo['epochs']):\n",
+    "    # Set model to training mode\n",
+    "    encoder.train(True)\n",
+    "\n",
+    "    # do a pass over the data\n",
+    "    # at last epoch get predicted embeddings and chem names\n",
+    "    if (epoch + 1) == combo['epochs']:\n",
+    "      average_loss, predicted_embeddings, output_name_encodings = train_one_epoch(\n",
+    "        train_dataset, device, encoder, encoder_criterion, encoder_optimizer, epoch, combo\n",
+    "        )\n",
+    "    else:\n",
+    "      average_loss = train_one_epoch(\n",
+    "        train_dataset, device, encoder, encoder_criterion, encoder_optimizer, epoch, combo\n",
+    "        )\n",
+    "\n",
+    "    epoch_val_loss = 0  \n",
+    "    # evaluate model on validation data\n",
+    "    encoder.eval() # Set model to evaluation mode\n",
+    "    with torch.no_grad():\n",
+    "      for val_batch, val_name_encodings, val_true_embeddings, val_spectra_indices in val_dataset:\n",
+    "        val_batch = val_batch.to(device)\n",
+    "        val_name_encodings = val_name_encodings.to(device)\n",
+    "        val_true_embeddings = val_true_embeddings.to(device)\n",
+    "\n",
+    "        val_batch_predicted_embeddings = encoder(val_batch)\n",
+    "\n",
+    "        val_loss = encoder_criterion(val_batch_predicted_embeddings, val_true_embeddings)\n",
+    "        # accumulate epoch validation loss\n",
+    "        epoch_val_loss += val_loss.item()\n",
+    "\n",
+    "    # divide by number of batches to calculate average loss\n",
+    "    val_average_loss = epoch_val_loss/len(val_dataset)\n",
+    "\n",
+    "    # log losses to wandb\n",
+    "    wandb.log({\"Encoder Training Loss\": average_loss, \"Encoder Validation Loss\": val_average_loss})\n",
+    "    # wandb.log({\"Encoder Training Loss\": average_loss})\n",
+    "\n",
+    "    if (epoch + 1) % 10 == 0:\n",
+    "      print('Epoch[{}/{}]:'.format(epoch+1, combo['epochs']))\n",
+    "      print(f'   Training loss: {average_loss}')\n",
+    "      print(f'   Validation loss: {val_average_loss}')\n",
+    "      print('-------------------------------------------')\n",
+    "\n",
+    "  if save_emb_pca_to_wandb:\n",
+    "    true_embeddings, predicted_embeddings_flattened, chem_names = preds_to_emb_pca_plot(predicted_embeddings, output_name_encodings, sorted_chem_names, name_smiles_embedding_df)\n",
+    "\n",
+    "  if average_loss < lowest_loss:\n",
+    "    best_hyperparams = combo\n",
+    "\n",
+    "  wandb.finish()\n",
+    "\n",
+    "print('Hyperparameters for best model: ')\n",
+    "for key in best_hyperparams:\n",
+    "  print('   ', key, ' : ', best_hyperparams[key])"
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
diff --git a/models/ims_encoder.ipynb b/models/ims_encoder.ipynb
index dd39e6cd..6f35ef1e 100644
--- a/models/ims_encoder.ipynb
+++ b/models/ims_encoder.ipynb
@@ -65,7 +65,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": 2,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -84,6 +84,215 @@
     "# mass_spec_encoder_generated_embeddings = mass_spec_encoder_generated_embeddings.drop('Unnamed: 0', axis=1)"
    ]
   },
+  {
+   "cell_type": "code",
+   "execution_count": 4,
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/html": [
+       "<div>\n",
+       "<style scoped>\n",
+       "    .dataframe tbody tr th:only-of-type {\n",
+       "        vertical-align: middle;\n",
+       "    }\n",
+       "\n",
+       "    .dataframe tbody tr th {\n",
+       "        vertical-align: top;\n",
+       "    }\n",
+       "\n",
+       "    .dataframe thead th {\n",
+       "        text-align: right;\n",
+       "    }\n",
+       "</style>\n",
+       "<table border=\"1\" class=\"dataframe\">\n",
+       "  <thead>\n",
+       "    <tr style=\"text-align: right;\">\n",
+       "      <th></th>\n",
+       "      <th>0</th>\n",
+       "      <th>1</th>\n",
+       "      <th>2</th>\n",
+       "      <th>3</th>\n",
+       "      <th>4</th>\n",
+       "      <th>5</th>\n",
+       "      <th>6</th>\n",
+       "      <th>7</th>\n",
+       "      <th>8</th>\n",
+       "      <th>9</th>\n",
+       "      <th>...</th>\n",
+       "      <th>503</th>\n",
+       "      <th>504</th>\n",
+       "      <th>505</th>\n",
+       "      <th>506</th>\n",
+       "      <th>507</th>\n",
+       "      <th>508</th>\n",
+       "      <th>509</th>\n",
+       "      <th>510</th>\n",
+       "      <th>511</th>\n",
+       "      <th>Label</th>\n",
+       "    </tr>\n",
+       "  </thead>\n",
+       "  <tbody>\n",
+       "    <tr>\n",
+       "      <th>0</th>\n",
+       "      <td>0.021717</td>\n",
+       "      <td>0.013678</td>\n",
+       "      <td>-0.124958</td>\n",
+       "      <td>0.377754</td>\n",
+       "      <td>-0.046985</td>\n",
+       "      <td>0.244335</td>\n",
+       "      <td>-0.287048</td>\n",
+       "      <td>-0.164717</td>\n",
+       "      <td>-0.064576</td>\n",
+       "      <td>-0.370969</td>\n",
+       "      <td>...</td>\n",
+       "      <td>-0.135776</td>\n",
+       "      <td>0.423812</td>\n",
+       "      <td>-0.000535</td>\n",
+       "      <td>-0.172896</td>\n",
+       "      <td>-0.050619</td>\n",
+       "      <td>-0.079060</td>\n",
+       "      <td>0.083757</td>\n",
+       "      <td>0.163587</td>\n",
+       "      <td>-0.326790</td>\n",
+       "      <td>Glycine</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>1</th>\n",
+       "      <td>0.092086</td>\n",
+       "      <td>0.005441</td>\n",
+       "      <td>0.052097</td>\n",
+       "      <td>-0.224653</td>\n",
+       "      <td>-0.066780</td>\n",
+       "      <td>0.239429</td>\n",
+       "      <td>-0.175937</td>\n",
+       "      <td>-0.382511</td>\n",
+       "      <td>-0.231119</td>\n",
+       "      <td>-0.178706</td>\n",
+       "      <td>...</td>\n",
+       "      <td>-0.125035</td>\n",
+       "      <td>0.624961</td>\n",
+       "      <td>-0.001381</td>\n",
+       "      <td>-0.286743</td>\n",
+       "      <td>-0.050950</td>\n",
+       "      <td>-0.184345</td>\n",
+       "      <td>0.168900</td>\n",
+       "      <td>0.288457</td>\n",
+       "      <td>-0.507141</td>\n",
+       "      <td>Tryptophan</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>2</th>\n",
+       "      <td>0.037631</td>\n",
+       "      <td>0.027620</td>\n",
+       "      <td>-0.225086</td>\n",
+       "      <td>0.041972</td>\n",
+       "      <td>-0.005555</td>\n",
+       "      <td>0.572334</td>\n",
+       "      <td>-0.127380</td>\n",
+       "      <td>0.005321</td>\n",
+       "      <td>-0.036205</td>\n",
+       "      <td>0.048941</td>\n",
+       "      <td>...</td>\n",
+       "      <td>-0.099907</td>\n",
+       "      <td>0.392833</td>\n",
+       "      <td>-0.000110</td>\n",
+       "      <td>-0.218671</td>\n",
+       "      <td>-0.022165</td>\n",
+       "      <td>0.493825</td>\n",
+       "      <td>0.022181</td>\n",
+       "      <td>-0.003747</td>\n",
+       "      <td>-0.131424</td>\n",
+       "      <td>Glutaric Acid</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>3</th>\n",
+       "      <td>0.094717</td>\n",
+       "      <td>0.006332</td>\n",
+       "      <td>0.020762</td>\n",
+       "      <td>0.648412</td>\n",
+       "      <td>-0.194657</td>\n",
+       "      <td>0.322575</td>\n",
+       "      <td>0.367796</td>\n",
+       "      <td>-0.412032</td>\n",
+       "      <td>-0.405478</td>\n",
+       "      <td>-0.128544</td>\n",
+       "      <td>...</td>\n",
+       "      <td>-0.325018</td>\n",
+       "      <td>0.611758</td>\n",
+       "      <td>-0.001166</td>\n",
+       "      <td>-0.351308</td>\n",
+       "      <td>-0.043634</td>\n",
+       "      <td>-0.545758</td>\n",
+       "      <td>0.240541</td>\n",
+       "      <td>0.385630</td>\n",
+       "      <td>-0.294906</td>\n",
+       "      <td>Benzyl Benzoate</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>4</th>\n",
+       "      <td>0.235307</td>\n",
+       "      <td>0.002806</td>\n",
+       "      <td>-0.166888</td>\n",
+       "      <td>0.166171</td>\n",
+       "      <td>-0.006953</td>\n",
+       "      <td>0.156601</td>\n",
+       "      <td>0.011887</td>\n",
+       "      <td>-0.108990</td>\n",
+       "      <td>-0.216767</td>\n",
+       "      <td>-0.576114</td>\n",
+       "      <td>...</td>\n",
+       "      <td>-0.047719</td>\n",
+       "      <td>0.894500</td>\n",
+       "      <td>0.000387</td>\n",
+       "      <td>-0.240181</td>\n",
+       "      <td>-0.137264</td>\n",
+       "      <td>-0.162995</td>\n",
+       "      <td>-0.371316</td>\n",
+       "      <td>0.074220</td>\n",
+       "      <td>-0.373865</td>\n",
+       "      <td>Biphenyl</td>\n",
+       "    </tr>\n",
+       "  </tbody>\n",
+       "</table>\n",
+       "<p>5 rows × 513 columns</p>\n",
+       "</div>"
+      ],
+      "text/plain": [
+       "          0         1         2         3         4         5         6  \\\n",
+       "0  0.021717  0.013678 -0.124958  0.377754 -0.046985  0.244335 -0.287048   \n",
+       "1  0.092086  0.005441  0.052097 -0.224653 -0.066780  0.239429 -0.175937   \n",
+       "2  0.037631  0.027620 -0.225086  0.041972 -0.005555  0.572334 -0.127380   \n",
+       "3  0.094717  0.006332  0.020762  0.648412 -0.194657  0.322575  0.367796   \n",
+       "4  0.235307  0.002806 -0.166888  0.166171 -0.006953  0.156601  0.011887   \n",
+       "\n",
+       "          7         8         9  ...       503       504       505       506  \\\n",
+       "0 -0.164717 -0.064576 -0.370969  ... -0.135776  0.423812 -0.000535 -0.172896   \n",
+       "1 -0.382511 -0.231119 -0.178706  ... -0.125035  0.624961 -0.001381 -0.286743   \n",
+       "2  0.005321 -0.036205  0.048941  ... -0.099907  0.392833 -0.000110 -0.218671   \n",
+       "3 -0.412032 -0.405478 -0.128544  ... -0.325018  0.611758 -0.001166 -0.351308   \n",
+       "4 -0.108990 -0.216767 -0.576114  ... -0.047719  0.894500  0.000387 -0.240181   \n",
+       "\n",
+       "        507       508       509       510       511            Label  \n",
+       "0 -0.050619 -0.079060  0.083757  0.163587 -0.326790          Glycine  \n",
+       "1 -0.050950 -0.184345  0.168900  0.288457 -0.507141       Tryptophan  \n",
+       "2 -0.022165  0.493825  0.022181 -0.003747 -0.131424    Glutaric Acid  \n",
+       "3 -0.043634 -0.545758  0.240541  0.385630 -0.294906  Benzyl Benzoate  \n",
+       "4 -0.137264 -0.162995 -0.371316  0.074220 -0.373865         Biphenyl  \n",
+       "\n",
+       "[5 rows x 513 columns]"
+      ]
+     },
+     "execution_count": 4,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "mass_spec_encoder_generated_embeddings.head()"
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": 5,
diff --git a/models/wandb/debug-internal.log b/models/wandb/debug-internal.log
index c2840df9..04330dc5 120000
--- a/models/wandb/debug-internal.log
+++ b/models/wandb/debug-internal.log
@@ -1 +1 @@
-run-20241210_003145-ngvq1jdz/logs/debug-internal.log
\ No newline at end of file
+run-20241212_125818-sboq9mw1/logs/debug-internal.log
\ No newline at end of file
diff --git a/models/wandb/debug.log b/models/wandb/debug.log
index c154948b..cd6f93a1 120000
--- a/models/wandb/debug.log
+++ b/models/wandb/debug.log
@@ -1 +1 @@
-run-20241210_003145-ngvq1jdz/logs/debug.log
\ No newline at end of file
+run-20241212_125818-sboq9mw1/logs/debug.log
\ No newline at end of file
diff --git a/models/wandb/latest-run b/models/wandb/latest-run
index b7a9e86a..bfedb7e9 120000
--- a/models/wandb/latest-run
+++ b/models/wandb/latest-run
@@ -1 +1 @@
-run-20241210_003145-ngvq1jdz
\ No newline at end of file
+run-20241212_125818-sboq9mw1
\ No newline at end of file
