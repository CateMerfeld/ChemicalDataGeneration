{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages and Files:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset \n",
    "\n",
    "import wandb\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "import itertools\n",
    "import io\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "import importlib\n",
    "import functions as f\n",
    "import random\n",
    "import GPUtil\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'functions' from '/home/cmdunham/ChemicalDataGeneration/models/functions.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload the functions module after updates\n",
    "importlib.reload(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../../../../mnt/c/Users/cmdunham/OneDrive/Documents/phd_program/ChemicalDataGeneration/data/ims_data/train_data.feather'\n",
    "train = pd.read_feather(filename)\n",
    "train = dd.from_pandas(train, npartitions=10)\n",
    "# filename = '../../../../mnt/c/Users/cmdunham/OneDrive/Documents/phd_program/ChemicalDataGeneration/data/ims_data/val_data.feather'\n",
    "# val = pd.read_feather(filename)\n",
    "# filename = '../../../../mnt/c/Users/cmdunham/OneDrive/Documents/phd_program/ChemicalDataGeneration/data/ims_data/test_data.feather'\n",
    "# test = pd.read_feather(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/train_carls.feather'\n",
    "train_carls = pd.read_feather(filename)\n",
    "train_carls = dd.from_pandas(train_carls, npartitions=10)\n",
    "# # # train_carls.drop('level_0', axis=1, inplace=True)\n",
    "# filename = '../data/val_carls.feather'\n",
    "# val_carls = pd.read_feather(filename)\n",
    "# # # val_carls.drop('level_0', axis=1, inplace=True)\n",
    "# filename = '../data/test_carls.feather'\n",
    "# test_carls = pd.read_feather(filename)\n",
    "# # # test_carls.drop('level_0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected GPU ID: 0\n",
      "  Name: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "  Memory Free: 7971.0 MB\n",
      "  Memory Used: 0.0 MB\n",
      "  GPU Load: 0.00%\n",
      "Current device ID:  cuda:0\n",
      "PyTorch current device ID: 0\n",
      "PyTorch current device name: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Get the list of GPUs\n",
    "    gpus = GPUtil.getGPUs()\n",
    "\n",
    "    # Find the GPU with the most free memory\n",
    "    best_gpu = max(gpus, key=lambda gpu: gpu.memoryFree)\n",
    "\n",
    "    # Print details about the selected GPU\n",
    "    print(f\"Selected GPU ID: {best_gpu.id}\")\n",
    "    print(f\"  Name: {best_gpu.name}\")\n",
    "    print(f\"  Memory Free: {best_gpu.memoryFree} MB\")\n",
    "    print(f\"  Memory Used: {best_gpu.memoryUsed} MB\")\n",
    "    print(f\"  GPU Load: {best_gpu.load * 100:.2f}%\")\n",
    "\n",
    "    # Set the device for later use\n",
    "    device = torch.device(f'cuda:{best_gpu.id}')\n",
    "    print('Current device ID: ', device)\n",
    "\n",
    "    # Set the current device in PyTorch\n",
    "    torch.cuda.set_device(best_gpu.id)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('Using CPU')\n",
    "\n",
    "# Confirm the currently selected device in PyTorch\n",
    "print(\"PyTorch current device ID:\", torch.cuda.current_device())\n",
    "print(\"PyTorch current device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_embeddings_tensor, train_carl_tensor, train_chem_encodings_tensor, train_carl_indices_tensor = f.create_dataset_tensors_for_generator(train_carls, train, device)\n",
    "# val_embeddings_tensor, val_carl_tensor, val_chem_encodings_tensor, val_carl_indices_tensor = f.create_dataset_tensors_for_generator(val_carls, val, device)\n",
    "# test_embeddings_tensor, test_carl_tensor, test_chem_encodings_tensor, test_carl_indices_tensor = f.create_dataset_tensors_for_generator(test_carls, test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_gen_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
