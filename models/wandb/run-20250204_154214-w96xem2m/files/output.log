Using device: cuda
--------------------------
--------------------------
New run with hyperparameters:
batch_size  :  32
epochs  :  500
learning_rate  :  1e-05
Saved best model at epoch 1
Epoch[1/500]:
   Training loss: 0.00216702499584794
   Validation loss: 0.0017324781400489847
-------------------------------------------
Saved best model at epoch 2
Saved best model at epoch 3
Saved best model at epoch 4
Saved best model at epoch 6
Saved best model at epoch 7
Epoch[10/500]:
   Training loss: 4.196416695239587e-05
   Validation loss: 0.001257915887738075
-------------------------------------------
Saved best model at epoch 13
Saved best model at epoch 18
Epoch[20/500]:
   Training loss: 2.7919471776652177e-05
   Validation loss: 0.0010027220045728449
-------------------------------------------
Saved best model at epoch 21
Saved best model at epoch 22
Saved best model at epoch 23
Saved best model at epoch 26
Saved best model at epoch 29
Saved best model at epoch 30
Epoch[30/500]:
   Training loss: 2.1053374953339143e-05
   Validation loss: 0.0006473234426581247
-------------------------------------------
Saved best model at epoch 31
Saved best model at epoch 33
Saved best model at epoch 35
Saved best model at epoch 37
Saved best model at epoch 38
Saved best model at epoch 39
Epoch[40/500]:
   Training loss: 1.4095060951269859e-05
   Validation loss: 0.00036886125946428703
-------------------------------------------
Saved best model at epoch 41
Saved best model at epoch 42
Saved best model at epoch 43
Saved best model at epoch 44
Saved best model at epoch 45
Saved best model at epoch 46
Saved best model at epoch 49
Epoch[50/500]:
   Training loss: 1.7198249259239053e-05
   Validation loss: 0.0002179817784446101
-------------------------------------------
Saved best model at epoch 51
Saved best model at epoch 54
Saved best model at epoch 56
Saved best model at epoch 59
Epoch[60/500]:
   Training loss: 9.587572899772904e-06
   Validation loss: 0.00028368039900785965
-------------------------------------------
Saved best model at epoch 62
Saved best model at epoch 63
Saved best model at epoch 65
Saved best model at epoch 68
Saved best model at epoch 70
Epoch[70/500]:
   Training loss: 1.0991162916107342e-05
   Validation loss: 4.615937780811859e-05
-------------------------------------------
Saved best model at epoch 74
Saved best model at epoch 77
Epoch[80/500]:
   Training loss: 9.41927802382013e-06
   Validation loss: 7.086772915241969e-05
-------------------------------------------
Epoch 00083: reducing learning rate of group 0 to 1.0000e-06.
Saved best model at epoch 88
Saved best model at epoch 89
Saved best model at epoch 90
Epoch[90/500]:
   Training loss: 3.536047873991706e-07
   Validation loss: 2.608371503016092e-05
-------------------------------------------
Saved best model at epoch 91
Saved best model at epoch 92
Saved best model at epoch 93
Saved best model at epoch 94
Saved best model at epoch 97
Saved best model at epoch 98
Saved best model at epoch 100
Epoch[100/500]:
   Training loss: 1.9579138579436127e-07
   Validation loss: 2.0223929108572765e-05
-------------------------------------------
Saved best model at epoch 102
Saved best model at epoch 104
Saved best model at epoch 108
Saved best model at epoch 110
Epoch[110/500]:
   Training loss: 1.2976213427334863e-07
   Validation loss: 1.7823755991923338e-05
-------------------------------------------
Epoch 00116: reducing learning rate of group 0 to 1.0000e-07.
Epoch[120/500]:
   Training loss: 7.176504452291837e-08
   Validation loss: 1.8425821177504424e-05
-------------------------------------------
Epoch 00122: reducing learning rate of group 0 to 1.0000e-08.
Epoch[130/500]:
   Training loss: 6.825703825659356e-08
   Validation loss: 1.8286929579556597e-05
-------------------------------------------
Validation loss has not improved in 20 epochs. Stopping training at epoch 131.
-------------------------------------------
-------------------------------------------
Dataset:  carls
Target Embeddings:  ChemNet
-------------------------------------------
-------------------------------------------
Encoder(
  (encoder): Sequential(
    (0): Linear(in_features=1676, out_features=1548, bias=True)
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
    (2): Linear(in_features=1548, out_features=1420, bias=True)
    (3): LeakyReLU(negative_slope=0.01, inplace=True)
    (4): Linear(in_features=1420, out_features=1292, bias=True)
    (5): LeakyReLU(negative_slope=0.01, inplace=True)
    (6): Linear(in_features=1292, out_features=1164, bias=True)
    (7): LeakyReLU(negative_slope=0.01, inplace=True)
    (8): Linear(in_features=1164, out_features=1036, bias=True)
    (9): LeakyReLU(negative_slope=0.01, inplace=True)
    (10): Linear(in_features=1036, out_features=908, bias=True)
    (11): LeakyReLU(negative_slope=0.01, inplace=True)
    (12): Linear(in_features=908, out_features=780, bias=True)
    (13): LeakyReLU(negative_slope=0.01, inplace=True)
    (14): Linear(in_features=780, out_features=652, bias=True)
    (15): LeakyReLU(negative_slope=0.01, inplace=True)
    (16): Linear(in_features=652, out_features=512, bias=True)
  )
)
-------------------------------------------
-------------------------------------------