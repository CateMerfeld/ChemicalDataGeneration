Using device: cuda
--------------------------
--------------------------
New run with hyperparameters:
batch_size  :  32
epochs  :  500
learning_rate  :  0.001
Saved best model at epoch 1
Epoch[1/500]:
   Training loss: 156360.671177335
   Validation loss: 152623.2371892526
-------------------------------------------
Saved best model at epoch 2
Saved best model at epoch 3
Saved best model at epoch 5
Traceback (most recent call last):
  File "/home/cmdunham/ChemicalDataGeneration/models/uninformative_embeddings/onehot_to_ims_universal_generator.py", line 78, in <module>
    f.train_generator(
  File "/home/cmdunham/ChemicalDataGeneration/models/functions.py", line 1052, in train_generator
    average_loss = train_one_epoch(
  File "/home/cmdunham/ChemicalDataGeneration/models/functions.py", line 225, in train_one_epoch
    for batch, name_encodings, true_embeddings, _ in train_dataset:
  File "/home/cmdunham/micromamba/envs/data_gen_venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/home/cmdunham/micromamba/envs/data_gen_venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 673, in _next_data
    index = self._next_index()  # may raise StopIteration
  File "/home/cmdunham/micromamba/envs/data_gen_venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 620, in _next_index
    return next(self._sampler_iter)  # may raise StopIteration
  File "/home/cmdunham/micromamba/envs/data_gen_venv/lib/python3.10/site-packages/torch/utils/data/sampler.py", line 283, in __iter__
    for idx in self.sampler:
  File "/home/cmdunham/micromamba/envs/data_gen_venv/lib/python3.10/site-packages/torch/utils/data/sampler.py", line 165, in __iter__
    yield from map(int, torch.randperm(n, generator=generator).numpy())
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/cmdunham/ChemicalDataGeneration/models/uninformative_embeddings/onehot_to_ims_universal_generator.py", line 78, in <module>
    f.train_generator(
  File "/home/cmdunham/ChemicalDataGeneration/models/functions.py", line 1052, in train_generator
    average_loss = train_one_epoch(
  File "/home/cmdunham/ChemicalDataGeneration/models/functions.py", line 225, in train_one_epoch
    for batch, name_encodings, true_embeddings, _ in train_dataset:
  File "/home/cmdunham/micromamba/envs/data_gen_venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/home/cmdunham/micromamba/envs/data_gen_venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 673, in _next_data
    index = self._next_index()  # may raise StopIteration
  File "/home/cmdunham/micromamba/envs/data_gen_venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 620, in _next_index
    return next(self._sampler_iter)  # may raise StopIteration
  File "/home/cmdunham/micromamba/envs/data_gen_venv/lib/python3.10/site-packages/torch/utils/data/sampler.py", line 283, in __iter__
    for idx in self.sampler:
  File "/home/cmdunham/micromamba/envs/data_gen_venv/lib/python3.10/site-packages/torch/utils/data/sampler.py", line 165, in __iter__
    yield from map(int, torch.randperm(n, generator=generator).numpy())
KeyboardInterrupt