Using device: cuda
--------------------------
--------------------------
New run with hyperparameters:
batch_size  :  32
epochs  :  500
learning_rate  :  1e-05
Saved best model at epoch 0
Saved best model at epoch 5
Saved best model at epoch 7
Saved best model at epoch 8
Saved best model at epoch 9
Epoch[10/500]:
   Training loss: 2.739862371586763e-05
   Validation loss: 0.005441585980402747
-------------------------------------------
Saved best model at epoch 10
Saved best model at epoch 11
Saved best model at epoch 13
Saved best model at epoch 14
Saved best model at epoch 15
Saved best model at epoch 16
Saved best model at epoch 17
Saved best model at epoch 18
Saved best model at epoch 19
Epoch[20/500]:
   Training loss: 1.7292486556735917e-05
   Validation loss: 0.002115698273504005
-------------------------------------------
Saved best model at epoch 20
Saved best model at epoch 21
Saved best model at epoch 22
Saved best model at epoch 23
Saved best model at epoch 24
Saved best model at epoch 25
Saved best model at epoch 26
Saved best model at epoch 27
Saved best model at epoch 28
Saved best model at epoch 29
Epoch[30/500]:
   Training loss: 1.0530042852746898e-05
   Validation loss: 0.0005741372414454798
-------------------------------------------
Saved best model at epoch 30
Saved best model at epoch 31
Saved best model at epoch 32
Saved best model at epoch 33
Saved best model at epoch 36
Saved best model at epoch 37
Saved best model at epoch 39
Epoch[40/500]:
   Training loss: 7.553720440336949e-06
   Validation loss: 0.00010800154091789012
-------------------------------------------
Saved best model at epoch 41
Saved best model at epoch 44
Saved best model at epoch 45
Saved best model at epoch 46
Epoch[50/500]:
   Training loss: 1.1803089771279264e-05
   Validation loss: 5.766819292517448e-05
-------------------------------------------
Saved best model at epoch 51
Saved best model at epoch 54
Saved best model at epoch 56
Epoch[60/500]:
   Training loss: 5.646221288542005e-06
   Validation loss: 2.2824333189989112e-05
-------------------------------------------
Epoch 00063: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00069: reducing learning rate of group 0 to 1.0000e-07.
Epoch[70/500]:
   Training loss: 7.015864207540029e-09
   Validation loss: 4.216071482359508e-05
-------------------------------------------
Validation loss has not improved in 15 epochs. Stopping training at epoch 72.
-------------------------------------------
-------------------------------------------
Dataset:  carls
Target Embeddings:  ChemNet
-------------------------------------------
-------------------------------------------
Encoder(
  (encoder): Sequential(
    (0): Linear(in_features=1676, out_features=1548, bias=True)
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
    (2): Linear(in_features=1548, out_features=1420, bias=True)
    (3): LeakyReLU(negative_slope=0.01, inplace=True)
    (4): Linear(in_features=1420, out_features=1292, bias=True)
    (5): LeakyReLU(negative_slope=0.01, inplace=True)
    (6): Linear(in_features=1292, out_features=1164, bias=True)
    (7): LeakyReLU(negative_slope=0.01, inplace=True)
    (8): Linear(in_features=1164, out_features=1036, bias=True)
    (9): LeakyReLU(negative_slope=0.01, inplace=True)
    (10): Linear(in_features=1036, out_features=908, bias=True)
    (11): LeakyReLU(negative_slope=0.01, inplace=True)
    (12): Linear(in_features=908, out_features=780, bias=True)
    (13): LeakyReLU(negative_slope=0.01, inplace=True)
    (14): Linear(in_features=780, out_features=652, bias=True)
    (15): LeakyReLU(negative_slope=0.01, inplace=True)
    (16): Linear(in_features=652, out_features=512, bias=True)
  )
)
-------------------------------------------
-------------------------------------------