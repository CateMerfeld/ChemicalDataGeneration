Using device: cuda
--------------------------
--------------------------
New run with hyperparameters:
batch_size  :  64
epochs  :  500
learning_rate  :  1e-06
Saved best model at epoch 1
Saved best model at epoch 2
Saved best model at epoch 3
Saved best model at epoch 4
Saved best model at epoch 5
Saved best model at epoch 6
Saved best model at epoch 7
Saved best model at epoch 8
Saved best model at epoch 9
Saved best model at epoch 10
Epoch[10/500]:
   Training loss: 0.0001462018757551041
   Validation loss: 0.0001328292451426964
-------------------------------------------
Saved best model at epoch 11
Saved best model at epoch 12
Saved best model at epoch 13
Saved best model at epoch 14
Saved best model at epoch 16
Saved best model at epoch 18
Saved best model at epoch 19
Saved best model at epoch 20
Epoch[20/500]:
   Training loss: 5.5474042898209864e-05
   Validation loss: 5.6061919512385745e-05
-------------------------------------------
Saved best model at epoch 22
Saved best model at epoch 23
Saved best model at epoch 26
Saved best model at epoch 27
Saved best model at epoch 30
Epoch[30/500]:
   Training loss: 3.393796659068168e-05
   Validation loss: 3.109068007367161e-05
-------------------------------------------
Saved best model at epoch 33
Saved best model at epoch 34
Saved best model at epoch 36
Saved best model at epoch 37
Saved best model at epoch 40
Epoch[40/500]:
   Training loss: 2.49176224237281e-05
   Validation loss: 2.323106139689618e-05
-------------------------------------------
Saved best model at epoch 41
Saved best model at epoch 44
Saved best model at epoch 46
Saved best model at epoch 48
Epoch[50/500]:
   Training loss: 2.0858281612803304e-05
   Validation loss: 1.952188755232218e-05
-------------------------------------------
Saved best model at epoch 51
Saved best model at epoch 52
Saved best model at epoch 54
Saved best model at epoch 60
Epoch[60/500]:
   Training loss: 1.5715779174577755e-05
   Validation loss: 1.5579691346923436e-05
-------------------------------------------
Saved best model at epoch 61
Saved best model at epoch 66
Saved best model at epoch 68
Epoch[70/500]:
   Training loss: 1.4005897531447986e-05
   Validation loss: 1.7713091573302243e-05
-------------------------------------------
Saved best model at epoch 72
Saved best model at epoch 73
Saved best model at epoch 76
Saved best model at epoch 77
Epoch[80/500]:
   Training loss: 9.056437175957938e-06
   Validation loss: 1.3102213730148989e-05
-------------------------------------------
Saved best model at epoch 82
Saved best model at epoch 84
Saved best model at epoch 86
Saved best model at epoch 90
Epoch[90/500]:
   Training loss: 9.019462767639421e-06
   Validation loss: 1.143861408865695e-05
-------------------------------------------
Saved best model at epoch 91
Saved best model at epoch 98
Saved best model at epoch 100
Epoch[100/500]:
   Training loss: 9.455404928767116e-06
   Validation loss: 1.04851455508173e-05
-------------------------------------------
Saved best model at epoch 108
Epoch[110/500]:
   Training loss: 1.0483997281850144e-05
   Validation loss: 1.0715214590253834e-05
-------------------------------------------
Saved best model at epoch 114
Saved best model at epoch 119
Epoch[120/500]:
   Training loss: 7.679994842947742e-06
   Validation loss: 1.072904919494939e-05
-------------------------------------------
Validation loss has not improved in 10 epochs. Stopping training at epoch 129.
-------------------------------------------
-------------------------------------------
Dataset:  IMS
Target Embeddings:  ChemNet
-------------------------------------------
-------------------------------------------
Encoder(
  (encoder): Sequential(
    (0): Linear(in_features=1676, out_features=1548, bias=True)
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
    (2): Linear(in_features=1548, out_features=1420, bias=True)
    (3): LeakyReLU(negative_slope=0.01, inplace=True)
    (4): Linear(in_features=1420, out_features=1292, bias=True)
    (5): LeakyReLU(negative_slope=0.01, inplace=True)
    (6): Linear(in_features=1292, out_features=1164, bias=True)
    (7): LeakyReLU(negative_slope=0.01, inplace=True)
    (8): Linear(in_features=1164, out_features=1036, bias=True)
    (9): LeakyReLU(negative_slope=0.01, inplace=True)
    (10): Linear(in_features=1036, out_features=908, bias=True)
    (11): LeakyReLU(negative_slope=0.01, inplace=True)
    (12): Linear(in_features=908, out_features=780, bias=True)
    (13): LeakyReLU(negative_slope=0.01, inplace=True)
    (14): Linear(in_features=780, out_features=652, bias=True)
    (15): LeakyReLU(negative_slope=0.01, inplace=True)
    (16): Linear(in_features=652, out_features=512, bias=True)
  )
)
-------------------------------------------
-------------------------------------------