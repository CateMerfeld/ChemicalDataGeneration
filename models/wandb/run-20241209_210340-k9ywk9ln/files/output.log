Using device: cuda
--------------------------
--------------------------
New run with hyperparameters:
batch_size  :  64
epochs  :  500
learning_rate  :  1e-05
Saved best model at epoch 1
Saved best model at epoch 2
Saved best model at epoch 3
Saved best model at epoch 4
Saved best model at epoch 5
Saved best model at epoch 6
Saved best model at epoch 7
Saved best model at epoch 8
Saved best model at epoch 9
Saved best model at epoch 10
Epoch[10/500]:
   Training loss: 0.0025969498580751035
   Validation loss: 0.0025462497681817227
-------------------------------------------
Saved best model at epoch 11
Saved best model at epoch 12
Saved best model at epoch 13
Saved best model at epoch 14
Saved best model at epoch 15
Saved best model at epoch 16
Saved best model at epoch 17
Saved best model at epoch 18
Saved best model at epoch 19
Saved best model at epoch 20
Epoch[20/500]:
   Training loss: 0.0013291555791583598
   Validation loss: 0.0015727442875041917
-------------------------------------------
Saved best model at epoch 21
Saved best model at epoch 22
Saved best model at epoch 23
Saved best model at epoch 24
Saved best model at epoch 25
Saved best model at epoch 26
Saved best model at epoch 27
Saved best model at epoch 28
Saved best model at epoch 29
Saved best model at epoch 30
Epoch[30/500]:
   Training loss: 0.0008047551525197615
   Validation loss: 0.0011998068138267784
-------------------------------------------
Saved best model at epoch 31
Saved best model at epoch 33
Saved best model at epoch 34
Saved best model at epoch 35
Saved best model at epoch 36
Saved best model at epoch 37
Saved best model at epoch 38
Saved best model at epoch 39
Saved best model at epoch 40
Epoch[40/500]:
   Training loss: 0.0005014943682733818
   Validation loss: 0.0010199009256579277
-------------------------------------------
Saved best model at epoch 41
Saved best model at epoch 42
Saved best model at epoch 43
Saved best model at epoch 44
Saved best model at epoch 45
Saved best model at epoch 47
Saved best model at epoch 48
Saved best model at epoch 49
Saved best model at epoch 50
Epoch[50/500]:
   Training loss: 0.00031610582202005354
   Validation loss: 0.0009211194555973634
-------------------------------------------
Saved best model at epoch 51
Saved best model at epoch 52
Saved best model at epoch 53
Saved best model at epoch 54
Saved best model at epoch 56
Saved best model at epoch 57
Saved best model at epoch 58
Saved best model at epoch 59
Saved best model at epoch 60
Epoch[60/500]:
   Training loss: 0.00019936555833932225
   Validation loss: 0.0008410992233729489
-------------------------------------------
Saved best model at epoch 61
Saved best model at epoch 63
Saved best model at epoch 64
Saved best model at epoch 65
Saved best model at epoch 66
Saved best model at epoch 67
Saved best model at epoch 69
Epoch[70/500]:
   Training loss: 0.00012396912263365768
   Validation loss: 0.0007845626139607811
-------------------------------------------
Saved best model at epoch 72
Saved best model at epoch 73
Saved best model at epoch 75
Saved best model at epoch 76
Saved best model at epoch 77
Saved best model at epoch 79
Saved best model at epoch 80
Epoch[80/500]:
   Training loss: 7.963007619146143e-05
   Validation loss: 0.0007527572095038721
-------------------------------------------
Saved best model at epoch 81
Saved best model at epoch 82
Saved best model at epoch 84
Saved best model at epoch 85
Saved best model at epoch 86
Saved best model at epoch 89
Epoch[90/500]:
   Training loss: 5.1932531362462206e-05
   Validation loss: 0.000751239679503603
-------------------------------------------
Saved best model at epoch 92
Saved best model at epoch 95
Saved best model at epoch 97
Saved best model at epoch 99
Epoch[100/500]:
   Training loss: 3.3798002939145e-05
   Validation loss: 0.0007163519115159859
-------------------------------------------
Saved best model at epoch 103
Saved best model at epoch 107
Epoch[110/500]:
   Training loss: 2.392902225192015e-05
   Validation loss: 0.0006992321433058079
-------------------------------------------
Saved best model at epoch 113
Saved best model at epoch 119
Epoch[120/500]:
   Training loss: 1.569049269092282e-05
   Validation loss: 0.0006807578819949798
-------------------------------------------
Saved best model at epoch 123
Saved best model at epoch 128
Epoch[130/500]:
   Training loss: 1.1655538485564637e-05
   Validation loss: 0.0006806564065390683
-------------------------------------------
Saved best model at epoch 131
Saved best model at epoch 136
Saved best model at epoch 139
Epoch[140/500]:
   Training loss: 8.946732459496688e-06
   Validation loss: 0.0006710202508337722
-------------------------------------------
Saved best model at epoch 143
Saved best model at epoch 144
Epoch[150/500]:
   Training loss: 7.936732513288724e-06
   Validation loss: 0.0006790516498653389
-------------------------------------------
Saved best model at epoch 151
Epoch[160/500]:
   Training loss: 5.661402183868571e-06
   Validation loss: 0.0006649691168477991
-------------------------------------------
Validation loss has not improved in 15 epochs. Stopping training at epoch 166.
-------------------------------------------
-------------------------------------------
Dataset:  MNIST
Target Embeddings:  ChemNet
-------------------------------------------
-------------------------------------------
Encoder(
  (encoder): Sequential(
    (0): Linear(in_features=784, out_features=716, bias=True)
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
    (2): Linear(in_features=716, out_features=648, bias=True)
    (3): LeakyReLU(negative_slope=0.01, inplace=True)
    (4): Linear(in_features=648, out_features=580, bias=True)
    (5): LeakyReLU(negative_slope=0.01, inplace=True)
    (6): Linear(in_features=580, out_features=512, bias=True)
  )
)
-------------------------------------------
-------------------------------------------