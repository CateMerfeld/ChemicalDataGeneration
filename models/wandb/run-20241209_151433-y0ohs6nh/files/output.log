Using device: cuda
--------------------------
--------------------------
New run with hyperparameters:
batch_size  :  64
epochs  :  500
learning_rate  :  1e-07
Saved best model at epoch 1
Saved best model at epoch 2
Saved best model at epoch 3
Saved best model at epoch 4
Saved best model at epoch 5
Saved best model at epoch 6
Saved best model at epoch 7
Saved best model at epoch 8
Saved best model at epoch 9
Saved best model at epoch 10
Epoch[10/500]:
   Training loss: 0.005137499309748754
   Validation loss: 0.006350749514992991
-------------------------------------------
Saved best model at epoch 11
Saved best model at epoch 12
Saved best model at epoch 13
Saved best model at epoch 14
Saved best model at epoch 15
Saved best model at epoch 16
Saved best model at epoch 17
Saved best model at epoch 18
Saved best model at epoch 19
Saved best model at epoch 20
Epoch[20/500]:
   Training loss: 0.0012347864238604787
   Validation loss: 0.0030394295389324444
-------------------------------------------
Saved best model at epoch 21
Saved best model at epoch 22
Saved best model at epoch 23
Saved best model at epoch 24
Saved best model at epoch 25
Saved best model at epoch 26
Saved best model at epoch 27
Saved best model at epoch 28
Saved best model at epoch 29
Saved best model at epoch 30
Epoch[30/500]:
   Training loss: 0.0004935465419882673
   Validation loss: 0.0023082400343339723
-------------------------------------------
Saved best model at epoch 31
Saved best model at epoch 32
Saved best model at epoch 33
Saved best model at epoch 34
Saved best model at epoch 35
Saved best model at epoch 36
Saved best model at epoch 37
Saved best model at epoch 38
Saved best model at epoch 39
Epoch[40/500]:
   Training loss: 0.00029781368009301615
   Validation loss: 0.0020891761381288485
-------------------------------------------
Saved best model at epoch 41
Saved best model at epoch 43
Saved best model at epoch 44
Saved best model at epoch 45
Saved best model at epoch 46
Saved best model at epoch 48
Saved best model at epoch 49
Saved best model at epoch 50
Epoch[50/500]:
   Training loss: 0.00020568021044169903
   Validation loss: 0.001971780629085923
-------------------------------------------
Saved best model at epoch 51
Saved best model at epoch 52
Saved best model at epoch 53
Saved best model at epoch 55
Saved best model at epoch 56
Saved best model at epoch 59
Epoch[60/500]:
   Training loss: 0.00015256717885239686
   Validation loss: 0.0018985023454253427
-------------------------------------------
Saved best model at epoch 61
Saved best model at epoch 64
Saved best model at epoch 65
Saved best model at epoch 66
Saved best model at epoch 68
Saved best model at epoch 69
Epoch[70/500]:
   Training loss: 0.00011956424387405402
   Validation loss: 0.001851432932308571
-------------------------------------------
Saved best model at epoch 71
Saved best model at epoch 72
Saved best model at epoch 73
Saved best model at epoch 74
Saved best model at epoch 75
Saved best model at epoch 76
Saved best model at epoch 78
Epoch[80/500]:
   Training loss: 9.747719244367882e-05
   Validation loss: 0.001792384357376532
-------------------------------------------
Saved best model at epoch 82
Saved best model at epoch 85
Saved best model at epoch 86
Saved best model at epoch 87
Epoch[90/500]:
   Training loss: 8.190981941680941e-05
   Validation loss: 0.0017652989628976652
-------------------------------------------
Saved best model at epoch 91
Saved best model at epoch 92
Saved best model at epoch 93
Saved best model at epoch 94
Saved best model at epoch 95
Saved best model at epoch 96
Saved best model at epoch 97
Saved best model at epoch 98
Saved best model at epoch 100
Epoch[100/500]:
   Training loss: 7.045387676822482e-05
   Validation loss: 0.0017048594278125605
-------------------------------------------
Saved best model at epoch 103
Saved best model at epoch 108
Saved best model at epoch 109
Epoch[110/500]:
   Training loss: 6.156933156733337e-05
   Validation loss: 0.0016922368618311181
-------------------------------------------
Saved best model at epoch 112
Saved best model at epoch 116
Saved best model at epoch 119
Epoch[120/500]:
   Training loss: 5.4454531193394986e-05
   Validation loss: 0.0016702914278131833
-------------------------------------------
Saved best model at epoch 121
Saved best model at epoch 122
Saved best model at epoch 126
Saved best model at epoch 128
Saved best model at epoch 130
Epoch[130/500]:
   Training loss: 4.880483119986988e-05
   Validation loss: 0.0016521056219172068
-------------------------------------------
Saved best model at epoch 131
Saved best model at epoch 132
Saved best model at epoch 135
Saved best model at epoch 138
Saved best model at epoch 139
Epoch[140/500]:
   Training loss: 4.403293743590617e-05
   Validation loss: 0.00163766971953574
-------------------------------------------
Saved best model at epoch 141
Saved best model at epoch 146
Saved best model at epoch 148
Saved best model at epoch 150
Epoch[150/500]:
   Training loss: 4.0093955478333135e-05
   Validation loss: 0.0016218048496566867
-------------------------------------------
Saved best model at epoch 153
Saved best model at epoch 154
Saved best model at epoch 155
Saved best model at epoch 157
Saved best model at epoch 158
Epoch[160/500]:
   Training loss: 3.670143677505672e-05
   Validation loss: 0.0016030876198046512
-------------------------------------------
Validation loss has not improved in 10 epochs. Stopping training at epoch 168.
-------------------------------------------
-------------------------------------------
Dataset:  IMS_excluded_chemical_test
Target Embeddings:  ChemNet
-------------------------------------------
-------------------------------------------
Encoder(
  (encoder): Sequential(
    (0): Linear(in_features=1676, out_features=1548, bias=True)
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
    (2): Linear(in_features=1548, out_features=1420, bias=True)
    (3): LeakyReLU(negative_slope=0.01, inplace=True)
    (4): Linear(in_features=1420, out_features=1292, bias=True)
    (5): LeakyReLU(negative_slope=0.01, inplace=True)
    (6): Linear(in_features=1292, out_features=1164, bias=True)
    (7): LeakyReLU(negative_slope=0.01, inplace=True)
    (8): Linear(in_features=1164, out_features=1036, bias=True)
    (9): LeakyReLU(negative_slope=0.01, inplace=True)
    (10): Linear(in_features=1036, out_features=908, bias=True)
    (11): LeakyReLU(negative_slope=0.01, inplace=True)
    (12): Linear(in_features=908, out_features=780, bias=True)
    (13): LeakyReLU(negative_slope=0.01, inplace=True)
    (14): Linear(in_features=780, out_features=652, bias=True)
    (15): LeakyReLU(negative_slope=0.01, inplace=True)
    (16): Linear(in_features=652, out_features=512, bias=True)
  )
)
-------------------------------------------
-------------------------------------------