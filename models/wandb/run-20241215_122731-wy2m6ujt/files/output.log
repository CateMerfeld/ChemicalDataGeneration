Using device: cuda
--------------------------
--------------------------
New run with hyperparameters:
batch_size  :  64
epochs  :  500
learning_rate  :  1e-05
Saved best model at epoch 1
Saved best model at epoch 2
Saved best model at epoch 3
Saved best model at epoch 4
Saved best model at epoch 5
Saved best model at epoch 7
Saved best model at epoch 10
Epoch[10/500]:
   Training loss: 7.579736407794366e-05
   Validation loss: 5.115047107611551e-05
-------------------------------------------
Saved best model at epoch 11
Saved best model at epoch 14
Saved best model at epoch 17
Epoch[20/500]:
   Training loss: 3.5019522566080426e-05
   Validation loss: 0.0003292494768145128
-------------------------------------------
Saved best model at epoch 21
Epoch 00027: reducing learning rate of group 0 to 1.0000e-06.
Saved best model at epoch 28
Saved best model at epoch 29
Saved best model at epoch 30
Epoch[30/500]:
   Training loss: 4.805108672694499e-06
   Validation loss: 1.004061184560075e-05
-------------------------------------------
Saved best model at epoch 31
Saved best model at epoch 32
Saved best model at epoch 33
Saved best model at epoch 36
Saved best model at epoch 37
Saved best model at epoch 38
Epoch[40/500]:
   Training loss: 2.945703872861096e-06
   Validation loss: 7.783493156380524e-06
-------------------------------------------
Saved best model at epoch 42
Saved best model at epoch 44
Saved best model at epoch 46
Epoch 00049: reducing learning rate of group 0 to 1.0000e-07.
Saved best model at epoch 50
Epoch[50/500]:
   Training loss: 1.950272702908919e-06
   Validation loss: 7.308104989598736e-06
-------------------------------------------
Saved best model at epoch 51
Saved best model at epoch 52
Saved best model at epoch 53
Saved best model at epoch 56
Saved best model at epoch 57
Saved best model at epoch 58
Saved best model at epoch 59
Epoch[60/500]:
   Training loss: 1.7704724045436322e-06
   Validation loss: 7.1334162785041194e-06
-------------------------------------------
Saved best model at epoch 62
Saved best model at epoch 63
Epoch 00064: reducing learning rate of group 0 to 1.0000e-08.
Saved best model at epoch 64
Saved best model at epoch 65
Saved best model at epoch 66
Saved best model at epoch 67
Saved best model at epoch 68
Saved best model at epoch 69
Saved best model at epoch 70
Epoch[70/500]:
   Training loss: 1.691590368407025e-06
   Validation loss: 7.071051679360719e-06
-------------------------------------------
Saved best model at epoch 71
Saved best model at epoch 72
Saved best model at epoch 75
Saved best model at epoch 76
Saved best model at epoch 79
Epoch[80/500]:
   Training loss: 1.6865784254098848e-06
   Validation loss: 7.0582436983488306e-06
-------------------------------------------
Saved best model at epoch 81
Saved best model at epoch 84
Saved best model at epoch 85
Saved best model at epoch 87
Saved best model at epoch 88
Saved best model at epoch 90
Epoch[90/500]:
   Training loss: 1.6809502857580552e-06
   Validation loss: 7.049325982048596e-06
-------------------------------------------
Saved best model at epoch 93
Saved best model at epoch 95
Saved best model at epoch 96
Saved best model at epoch 97
Saved best model at epoch 99
Saved best model at epoch 100
Epoch[100/500]:
   Training loss: 1.6765387856307238e-06
   Validation loss: 7.040213757230931e-06
-------------------------------------------
Saved best model at epoch 101
Saved best model at epoch 103
Saved best model at epoch 104
Saved best model at epoch 105
Saved best model at epoch 107
Saved best model at epoch 108
Epoch[110/500]:
   Training loss: 1.6722217330426907e-06
   Validation loss: 7.035689766429935e-06
-------------------------------------------
Saved best model at epoch 111
Saved best model at epoch 112
Saved best model at epoch 118
Epoch[120/500]:
   Training loss: 1.6678898170695367e-06
   Validation loss: 7.02710650341693e-06
-------------------------------------------
Saved best model at epoch 121
Saved best model at epoch 124
Epoch[130/500]:
   Training loss: 1.6639017916009257e-06
   Validation loss: 7.0222877414300445e-06
-------------------------------------------
Saved best model at epoch 131
Saved best model at epoch 133
Saved best model at epoch 135
Saved best model at epoch 136
Saved best model at epoch 137
Epoch[140/500]:
   Training loss: 1.6592208918417297e-06
   Validation loss: 7.015908560992011e-06
-------------------------------------------
Validation loss has not improved in 10 epochs. Stopping training at epoch 147.
-------------------------------------------
-------------------------------------------
Dataset:  IMS
Target Embeddings:  ChemNet
-------------------------------------------
-------------------------------------------
Encoder(
  (encoder): Sequential(
    (0): Linear(in_features=1676, out_features=1548, bias=True)
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
    (2): Linear(in_features=1548, out_features=1420, bias=True)
    (3): LeakyReLU(negative_slope=0.01, inplace=True)
    (4): Linear(in_features=1420, out_features=1292, bias=True)
    (5): LeakyReLU(negative_slope=0.01, inplace=True)
    (6): Linear(in_features=1292, out_features=1164, bias=True)
    (7): LeakyReLU(negative_slope=0.01, inplace=True)
    (8): Linear(in_features=1164, out_features=1036, bias=True)
    (9): LeakyReLU(negative_slope=0.01, inplace=True)
    (10): Linear(in_features=1036, out_features=908, bias=True)
    (11): LeakyReLU(negative_slope=0.01, inplace=True)
    (12): Linear(in_features=908, out_features=780, bias=True)
    (13): LeakyReLU(negative_slope=0.01, inplace=True)
    (14): Linear(in_features=780, out_features=652, bias=True)
    (15): LeakyReLU(negative_slope=0.01, inplace=True)
    (16): Linear(in_features=652, out_features=512, bias=True)
  )
)
-------------------------------------------
-------------------------------------------