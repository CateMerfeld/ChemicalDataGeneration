Using device: cuda
--------------------------
--------------------------
New run with hyperparameters:
batch_size  :  32
epochs  :  500
learning_rate  :  1e-05
Saved best model at epoch 0
Saved best model at epoch 2
Saved best model at epoch 5
Saved best model at epoch 6
Saved best model at epoch 8
Saved best model at epoch 9
Epoch[10/500]:
   Training loss: 3.155528308338299e-05
   Validation loss: 0.005515008356908941
-------------------------------------------
Saved best model at epoch 10
Saved best model at epoch 11
Saved best model at epoch 12
Saved best model at epoch 13
Saved best model at epoch 14
Saved best model at epoch 15
Saved best model at epoch 16
Saved best model at epoch 17
Saved best model at epoch 18
Saved best model at epoch 19
Epoch[20/500]:
   Training loss: 1.6286902632655455e-05
   Validation loss: 0.0023647392124897457
-------------------------------------------
Saved best model at epoch 20
Saved best model at epoch 21
Saved best model at epoch 22
Saved best model at epoch 24
Saved best model at epoch 25
Saved best model at epoch 26
Saved best model at epoch 27
Saved best model at epoch 28
Saved best model at epoch 29
Epoch[30/500]:
   Training loss: 1.227230714588777e-05
   Validation loss: 0.0005364901729860115
-------------------------------------------
Saved best model at epoch 30
Saved best model at epoch 31
Saved best model at epoch 32
Saved best model at epoch 33
Saved best model at epoch 35
Saved best model at epoch 36
Saved best model at epoch 37
Saved best model at epoch 39
Epoch[40/500]:
   Training loss: 8.11640236669751e-06
   Validation loss: 8.850065761092807e-05
-------------------------------------------
Saved best model at epoch 41
Saved best model at epoch 43
Saved best model at epoch 44
Saved best model at epoch 47
Epoch[50/500]:
   Training loss: 8.42028564224568e-06
   Validation loss: 7.263426465013389e-05
-------------------------------------------
Saved best model at epoch 50
Saved best model at epoch 55
Epoch[60/500]:
   Training loss: 8.365593450016591e-06
   Validation loss: 5.125517277790705e-05
-------------------------------------------
Epoch 00062: reducing learning rate of group 0 to 1.0000e-06.
Saved best model at epoch 63
Saved best model at epoch 64
Saved best model at epoch 65
Saved best model at epoch 66
Saved best model at epoch 67
Epoch[70/500]:
   Training loss: 8.260363688303376e-09
   Validation loss: 1.1017182714260837e-05
-------------------------------------------
Saved best model at epoch 71
Saved best model at epoch 73
Epoch 00080: reducing learning rate of group 0 to 1.0000e-07.
Epoch[80/500]:
   Training loss: 3.312832094259011e-09
   Validation loss: 1.1245719991704557e-05
-------------------------------------------
Epoch 00086: reducing learning rate of group 0 to 1.0000e-08.
Validation loss has not improved in 15 epochs. Stopping training at epoch 89.
-------------------------------------------
-------------------------------------------
Dataset:  carls
Target Embeddings:  ChemNet
-------------------------------------------
-------------------------------------------
Encoder(
  (encoder): Sequential(
    (0): Linear(in_features=1676, out_features=1548, bias=True)
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
    (2): Linear(in_features=1548, out_features=1420, bias=True)
    (3): LeakyReLU(negative_slope=0.01, inplace=True)
    (4): Linear(in_features=1420, out_features=1292, bias=True)
    (5): LeakyReLU(negative_slope=0.01, inplace=True)
    (6): Linear(in_features=1292, out_features=1164, bias=True)
    (7): LeakyReLU(negative_slope=0.01, inplace=True)
    (8): Linear(in_features=1164, out_features=1036, bias=True)
    (9): LeakyReLU(negative_slope=0.01, inplace=True)
    (10): Linear(in_features=1036, out_features=908, bias=True)
    (11): LeakyReLU(negative_slope=0.01, inplace=True)
    (12): Linear(in_features=908, out_features=780, bias=True)
    (13): LeakyReLU(negative_slope=0.01, inplace=True)
    (14): Linear(in_features=780, out_features=652, bias=True)
    (15): LeakyReLU(negative_slope=0.01, inplace=True)
    (16): Linear(in_features=652, out_features=512, bias=True)
  )
)
-------------------------------------------
-------------------------------------------