
Using device: cuda
Total training loss:  13.318939268414397
Num training batches:  1044
Total validation loss:  0.18194543360732496
Num validation batches:  116
Epoch[1/10]:
   Training loss: 3.2659467937874385
   Validation loss: 0.40153475002995853
-------------------------------------------
Total training loss:  0.7750337214092724
Num training batches:  1044
Total validation loss:  0.05390954465838149
Num validation batches:  116
Epoch[2/10]:
   Training loss: 0.19004658302756106
   Validation loss: 0.11897278821160054
-------------------------------------------
Total training loss:  0.33045301027595997
Num training batches:  1044
Total validation loss:  0.06380454590544105
Num validation batches:  116
Epoch[3/10]:
   Training loss: 0.0810306232094308
   Validation loss: 0.14081003234304232
-------------------------------------------
Total training loss:  0.21781828669190872
Num training batches:  1044
Total validation loss:  0.021335458142857533
Num validation batches:  116
Epoch[4/10]:
   Training loss: 0.05341138064475923
   Validation loss: 0.04708514900492697
-------------------------------------------
Total training loss:  0.15400645563204307
Num training batches:  1044
Total validation loss:  0.01669487926119473
Num validation batches:  116
Epoch[5/10]:
   Training loss: 0.03776403509751248
   Validation loss: 0.03684387147298147
-------------------------------------------
Total training loss:  0.12611425050272373
Num training batches:  1044
Total validation loss:  0.012164627107267734
Num validation batches:  116
Epoch[6/10]:
   Training loss: 0.03092456717308168
   Validation loss: 0.026846073616039138
-------------------------------------------
Total training loss:  0.09868324409035267
Num training batches:  1044
Total validation loss:  0.012026862168568186
Num validation batches:  116
Epoch[7/10]:
   Training loss: 0.024198190121772302
   Validation loss: 0.026542040647874618
-------------------------------------------
Total training loss:  0.09393574807836558
Num training batches:  1044
Total validation loss:  0.01587602517247433
Num validation batches:  116
Epoch[8/10]:
   Training loss: 0.023034053168641367
   Validation loss: 0.03503674520821921
-------------------------------------------
Total training loss:  0.08314025544677861
Num training batches:  1044
Total validation loss:  0.02002800863556331
Num validation batches:  116
Epoch[9/10]:
   Training loss: 0.020386882561662188
   Validation loss: 0.04419974319572593
-------------------------------------------
Total training loss:  0.08653637566203543
Num training batches:  1044
Total validation loss:  0.01622471012524329
Num validation batches:  116
Epoch[10/10]:
   Training loss: 0.021219647671916732
   Validation loss: 0.03580625682812313
-------------------------------------------