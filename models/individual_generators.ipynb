{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages and Files:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset \n",
    "\n",
    "import wandb\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "import itertools\n",
    "import io\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "import importlib\n",
    "import functions as f\n",
    "import random\n",
    "import GPUtil\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'functions' from '/home/cmdunham/ChemicalDataGeneration/models/functions.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload the functions module after updates\n",
    "importlib.reload(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = '../../../../mnt/c/Users/cmdunham/OneDrive/Documents/phd_program/ChemicalDataGeneration/data/ims_data/train_data.feather'\n",
    "# train = pd.read_feather(filename)\n",
    "# train = dd.from_pandas(train, npartitions=10)\n",
    "# # filename = '../../../../mnt/c/Users/cmdunham/OneDrive/Documents/phd_program/ChemicalDataGeneration/data/ims_data/val_data.feather'\n",
    "# # val = pd.read_feather(filename)\n",
    "# # filename = '../../../../mnt/c/Users/cmdunham/OneDrive/Documents/phd_program/ChemicalDataGeneration/data/ims_data/test_data.feather'\n",
    "# # test = pd.read_feather(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/ims_data/train_data.feather'\n",
    "train = pd.read_feather(file_path)\n",
    "\n",
    "file_path = '../data/ims_data/val_data.feather'\n",
    "val = pd.read_feather(file_path)\n",
    "\n",
    "file_path = '../data/ims_data/test_data.feather'\n",
    "test = pd.read_feather(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/carls/train_carls.feather'\n",
    "train_carls = pd.read_feather(file_path)\n",
    "train_carls.drop('level_0', axis=1, inplace=True)\n",
    "\n",
    "file_path = '../data/carls/val_carls.feather'\n",
    "val_carls = pd.read_feather(file_path)\n",
    "val_carls.drop('level_0', axis=1, inplace=True)\n",
    "\n",
    "file_path = '../data/carls/test_carls.feather'\n",
    "test_carls = pd.read_feather(file_path)\n",
    "test_carls.drop('level_0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "Not an Arrow file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeather\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfeather\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Replace 'your_file.feather' with the correct file path\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mfeather\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m train_embeddings\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\cmdunham\\OneDrive\\Documents\\phd_program\\ChemicalDataGeneration\\data_gen_venv\\lib\\site-packages\\pyarrow\\feather.py:252\u001b[0m, in \u001b[0;36mread_table\u001b[1;34m(source, columns, memory_map, use_threads)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_table\u001b[39m(source, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, use_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    232\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03m    Read a pyarrow.Table from Feather format\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m        The contents of the Feather file as a pyarrow.Table\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 252\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43m_feather\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFeatherReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_memory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Users\\cmdunham\\OneDrive\\Documents\\phd_program\\ChemicalDataGeneration\\data_gen_venv\\lib\\site-packages\\pyarrow\\_feather.pyx:79\u001b[0m, in \u001b[0;36mpyarrow._feather.FeatherReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\cmdunham\\OneDrive\\Documents\\phd_program\\ChemicalDataGeneration\\data_gen_venv\\lib\\site-packages\\pyarrow\\error.pxi:155\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\cmdunham\\OneDrive\\Documents\\phd_program\\ChemicalDataGeneration\\data_gen_venv\\lib\\site-packages\\pyarrow\\error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowInvalid\u001b[0m: Not an Arrow file"
     ]
    }
   ],
   "source": [
    "file_path = '../data/ims_data/avg_bkg_carl_encoder_train_embeddings.feather'\n",
    "train_embeddings = pd.to_feather(file_path)\n",
    "# train_embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del val, val_carls, test, test_carls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected GPU ID: 0\n",
      "  Name: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "  Memory Free: 6785.0 MB\n",
      "  Memory Used: 1173.0 MB\n",
      "  GPU Load: 0.00%\n",
      "Current device ID:  cuda:0\n",
      "PyTorch current device ID: 0\n",
      "PyTorch current device name: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Get the list of GPUs\n",
    "    gpus = GPUtil.getGPUs()\n",
    "\n",
    "    # Find the GPU with the most free memory\n",
    "    best_gpu = max(gpus, key=lambda gpu: gpu.memoryFree)\n",
    "\n",
    "    # Print details about the selected GPU\n",
    "    print(f\"Selected GPU ID: {best_gpu.id}\")\n",
    "    print(f\"  Name: {best_gpu.name}\")\n",
    "    print(f\"  Memory Free: {best_gpu.memoryFree} MB\")\n",
    "    print(f\"  Memory Used: {best_gpu.memoryUsed} MB\")\n",
    "    print(f\"  GPU Load: {best_gpu.load * 100:.2f}%\")\n",
    "\n",
    "    # Set the device for later use\n",
    "    device = torch.device(f'cuda:{best_gpu.id}')\n",
    "    print('Current device ID: ', device)\n",
    "\n",
    "    # Set the current device in PyTorch\n",
    "    torch.cuda.set_device(best_gpu.id)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('Using CPU')\n",
    "\n",
    "# Confirm the currently selected device in PyTorch\n",
    "print(\"PyTorch current device ID:\", torch.cuda.current_device())\n",
    "print(\"PyTorch current device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>p_184</th>\n",
       "      <th>p_185</th>\n",
       "      <th>p_186</th>\n",
       "      <th>p_187</th>\n",
       "      <th>p_188</th>\n",
       "      <th>p_189</th>\n",
       "      <th>p_190</th>\n",
       "      <th>p_191</th>\n",
       "      <th>...</th>\n",
       "      <th>n_1021</th>\n",
       "      <th>Label</th>\n",
       "      <th>DEB</th>\n",
       "      <th>DEM</th>\n",
       "      <th>DMMP</th>\n",
       "      <th>DPM</th>\n",
       "      <th>DtBP</th>\n",
       "      <th>JP8</th>\n",
       "      <th>MES</th>\n",
       "      <th>TEPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>287346</td>\n",
       "      <td>1333416</td>\n",
       "      <td>81.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>TEPO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>244422</td>\n",
       "      <td>1226215</td>\n",
       "      <td>81.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TEPO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>320966</td>\n",
       "      <td>1430326</td>\n",
       "      <td>85.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TEPO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>231490</td>\n",
       "      <td>1191507</td>\n",
       "      <td>130.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>TEPO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119707</td>\n",
       "      <td>689897</td>\n",
       "      <td>55.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>DEB</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1687 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    index  p_184  p_185  p_186  p_187  p_188  p_189  p_190  \\\n",
       "0      287346  1333416   81.0   84.0   88.0   93.0   99.0  104.0  110.0   \n",
       "1      244422  1226215   81.0   84.0   87.0   90.0   92.0   97.0  100.0   \n",
       "2      320966  1430326   85.0   88.0   91.0   96.0   98.0  101.0  106.0   \n",
       "3      231490  1191507  130.0  133.0  138.0  144.0  149.0  156.0  166.0   \n",
       "4      119707   689897   55.0   58.0   60.0   62.0   66.0   68.0   70.0   \n",
       "\n",
       "   p_191  ...  n_1021  Label  DEB  DEM  DMMP  DPM  DtBP  JP8  MES  TEPO  \n",
       "0  115.0  ...    -4.0   TEPO  0.0  0.0   0.0  0.0   0.0  0.0  0.0   1.0  \n",
       "1  106.0  ...     2.0   TEPO  0.0  0.0   0.0  0.0   0.0  0.0  0.0   1.0  \n",
       "2  110.0  ...     2.0   TEPO  0.0  0.0   0.0  0.0   0.0  0.0  0.0   1.0  \n",
       "3  175.0  ...     8.0   TEPO  0.0  0.0   0.0  0.0   0.0  0.0  0.0   1.0  \n",
       "4   71.0  ...   -17.0    DEB  1.0  0.0   0.0  0.0   0.0  0.0  0.0   0.0  \n",
       "\n",
       "[5 rows x 1687 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sup\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_embeddings_tensor, train_carl_tensor, train_chem_encodings_tensor, train_carl_indices_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_dataset_tensors_for_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_carls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# val_embeddings_tensor, val_carl_tensor, val_chem_encodings_tensor, val_carl_indices_tensor = f.create_dataset_tensors_for_generator(val_carls, val, device)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# test_embeddings_tensor, test_carl_tensor, test_chem_encodings_tensor, test_carl_indices_tensor = f.create_dataset_tensors_for_generator(test_carls, test, device)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cmdunham\\OneDrive\\Documents\\phd_program\\ChemicalDataGeneration\\models\\functions.py:1346\u001b[0m, in \u001b[0;36mcreate_dataset_tensors_for_generator\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msup\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1344\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m carl_dataset\n\u001b[1;32m-> 1346\u001b[0m embeddings_preds \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_preds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m   1347\u001b[0m carls \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(carls\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhello\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool."
     ]
    }
   ],
   "source": [
    "train_embeddings_tensor, train_carl_tensor, train_chem_encodings_tensor, train_carl_indices_tensor = f.create_dataset_tensors_for_generator(train_carls, train, device)\n",
    "# val_embeddings_tensor, val_carl_tensor, val_chem_encodings_tensor, val_carl_indices_tensor = f.create_dataset_tensors_for_generator(val_carls, val, device)\n",
    "# test_embeddings_tensor, test_carl_tensor, test_chem_encodings_tensor, test_carl_indices_tensor = f.create_dataset_tensors_for_generator(test_carls, test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_gen_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
