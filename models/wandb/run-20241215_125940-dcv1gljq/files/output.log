Using device: cuda
--------------------------
--------------------------
New run with hyperparameters:
batch_size  :  64
epochs  :  500
learning_rate  :  1e-05
Saved best model at epoch 1
Saved best model at epoch 3
Saved best model at epoch 5
Saved best model at epoch 6
Saved best model at epoch 10
Epoch[10/500]:
   Training loss: 6.062117196524913e-05
   Validation loss: 2.5157226914506485e-05
-------------------------------------------
Saved best model at epoch 16
Epoch[20/500]:
   Training loss: 3.836389096422698e-05
   Validation loss: 3.4220929445914785e-05
-------------------------------------------
Epoch 00022: reducing learning rate of group 0 to 1.0000e-06.
Saved best model at epoch 23
Saved best model at epoch 25
Saved best model at epoch 26
Saved best model at epoch 28
Saved best model at epoch 30
Epoch[30/500]:
   Training loss: 3.855743158063026e-06
   Validation loss: 8.046485016957117e-06
-------------------------------------------
Saved best model at epoch 31
Saved best model at epoch 33
Saved best model at epoch 35
Saved best model at epoch 36
Saved best model at epoch 38
Saved best model at epoch 39
Epoch[40/500]:
   Training loss: 2.919524466804444e-06
   Validation loss: 7.174230290925792e-06
-------------------------------------------
Saved best model at epoch 44
Saved best model at epoch 50
Epoch[50/500]:
   Training loss: 2.4900585302915096e-06
   Validation loss: 6.865450313225437e-06
-------------------------------------------
Saved best model at epoch 51
Saved best model at epoch 52
Saved best model at epoch 56
Saved best model at epoch 57
Epoch[60/500]:
   Training loss: 1.988277059460727e-06
   Validation loss: 6.922447922581916e-06
-------------------------------------------
Saved best model at epoch 62
Saved best model at epoch 66
Epoch[70/500]:
   Training loss: 1.7999362886212595e-06
   Validation loss: 6.703472853398182e-06
-------------------------------------------
Epoch 00072: reducing learning rate of group 0 to 1.0000e-07.
Saved best model at epoch 73
Saved best model at epoch 74
Saved best model at epoch 75
Saved best model at epoch 76
Saved best model at epoch 77
Epoch[80/500]:
   Training loss: 1.4018745428183461e-06
   Validation loss: 6.301226249601113e-06
-------------------------------------------
Saved best model at epoch 81
Saved best model at epoch 86
Saved best model at epoch 88
Epoch[90/500]:
   Training loss: 1.3755189488438296e-06
   Validation loss: 6.26250037320687e-06
-------------------------------------------
Saved best model at epoch 94
Saved best model at epoch 97
Epoch[100/500]:
   Training loss: 1.357571042490301e-06
   Validation loss: 6.241341628034666e-06
-------------------------------------------
Epoch 00103: reducing learning rate of group 0 to 1.0000e-08.
Saved best model at epoch 104
Epoch[110/500]:
   Training loss: 1.3124875471580616e-06
   Validation loss: 6.216660300070231e-06
-------------------------------------------
Saved best model at epoch 114
Saved best model at epoch 116
Epoch[120/500]:
   Training loss: 1.3100540886607512e-06
   Validation loss: 6.215319378581918e-06
-------------------------------------------
Saved best model at epoch 122
Saved best model at epoch 127
Epoch[130/500]:
   Training loss: 1.3081989530715537e-06
   Validation loss: 6.213808371677237e-06
-------------------------------------------
Saved best model at epoch 135
Saved best model at epoch 138
Epoch[140/500]:
   Training loss: 1.306183789149586e-06
   Validation loss: 6.213237135927134e-06
-------------------------------------------
Saved best model at epoch 143
Saved best model at epoch 144
Epoch[150/500]:
   Training loss: 1.3043894720132094e-06
   Validation loss: 6.21092617688571e-06
-------------------------------------------
Saved best model at epoch 151
Saved best model at epoch 152
Saved best model at epoch 159
Epoch[160/500]:
   Training loss: 1.3023760058408425e-06
   Validation loss: 6.211286370383594e-06
-------------------------------------------
Saved best model at epoch 162
Saved best model at epoch 163
Saved best model at epoch 169
Epoch[170/500]:
   Training loss: 1.3006324228045428e-06
   Validation loss: 6.2069493762839155e-06
-------------------------------------------
Saved best model at epoch 175
Saved best model at epoch 178
Saved best model at epoch 179
Epoch[180/500]:
   Training loss: 1.2989472866717774e-06
   Validation loss: 6.204989705647433e-06
-------------------------------------------
Validation loss has not improved in 10 epochs. Stopping training at epoch 189.
-------------------------------------------
-------------------------------------------
Dataset:  IMS
Target Embeddings:  ChemNet
-------------------------------------------
-------------------------------------------
Encoder(
  (encoder): Sequential(
    (0): Linear(in_features=1676, out_features=1548, bias=True)
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
    (2): Linear(in_features=1548, out_features=1420, bias=True)
    (3): LeakyReLU(negative_slope=0.01, inplace=True)
    (4): Linear(in_features=1420, out_features=1292, bias=True)
    (5): LeakyReLU(negative_slope=0.01, inplace=True)
    (6): Linear(in_features=1292, out_features=1164, bias=True)
    (7): LeakyReLU(negative_slope=0.01, inplace=True)
    (8): Linear(in_features=1164, out_features=1036, bias=True)
    (9): LeakyReLU(negative_slope=0.01, inplace=True)
    (10): Linear(in_features=1036, out_features=908, bias=True)
    (11): LeakyReLU(negative_slope=0.01, inplace=True)
    (12): Linear(in_features=908, out_features=780, bias=True)
    (13): LeakyReLU(negative_slope=0.01, inplace=True)
    (14): Linear(in_features=780, out_features=652, bias=True)
    (15): LeakyReLU(negative_slope=0.01, inplace=True)
    (16): Linear(in_features=652, out_features=512, bias=True)
  )
)
-------------------------------------------
-------------------------------------------