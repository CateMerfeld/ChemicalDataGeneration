Using device: cuda
--------------------------
--------------------------
New run with hyperparameters:
batch_size  :  32
epochs  :  500
learning_rate  :  1e-05
Saved best model at epoch 1
Saved best model at epoch 2
Saved best model at epoch 3
Saved best model at epoch 5
Epoch[10/500]:
   Training loss: 5.384983034336727e-05
   Validation loss: 7.512345855149824e-05
-------------------------------------------
Saved best model at epoch 11
Saved best model at epoch 18
Epoch[20/500]:
   Training loss: 3.1747609613904014e-05
   Validation loss: 4.666512693308411e-05
-------------------------------------------
Epoch 00024: reducing learning rate of group 0 to 1.0000e-06.
Saved best model at epoch 25
Saved best model at epoch 26
Saved best model at epoch 27
Saved best model at epoch 28
Saved best model at epoch 29
Saved best model at epoch 30
Epoch[30/500]:
   Training loss: 2.6637609049166716e-06
   Validation loss: 1.0246020043958026e-05
-------------------------------------------
Saved best model at epoch 31
Saved best model at epoch 32
Epoch 00033: reducing learning rate of group 0 to 1.0000e-07.
Saved best model at epoch 34
Saved best model at epoch 35
Epoch 00039: reducing learning rate of group 0 to 1.0000e-08.
Epoch[40/500]:
   Training loss: 1.7544635830435324e-06
   Validation loss: 9.597549847704802e-06
-------------------------------------------
Saved best model at epoch 41
Saved best model at epoch 42
Saved best model at epoch 43
Saved best model at epoch 44
Epoch[50/500]:
   Training loss: 1.743570344305569e-06
   Validation loss: 9.591760524262705e-06
-------------------------------------------
Saved best model at epoch 54
Epoch[60/500]:
   Training loss: 1.7345742398192299e-06
   Validation loss: 9.590475687198378e-06
-------------------------------------------
Validation loss has not improved in 10 epochs. Stopping training at epoch 64.
-------------------------------------------
-------------------------------------------
Dataset:  IMS
Target Embeddings:  ChemNet
-------------------------------------------
-------------------------------------------
Encoder(
  (encoder): Sequential(
    (0): Linear(in_features=1676, out_features=1548, bias=True)
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
    (2): Linear(in_features=1548, out_features=1420, bias=True)
    (3): LeakyReLU(negative_slope=0.01, inplace=True)
    (4): Linear(in_features=1420, out_features=1292, bias=True)
    (5): LeakyReLU(negative_slope=0.01, inplace=True)
    (6): Linear(in_features=1292, out_features=1164, bias=True)
    (7): LeakyReLU(negative_slope=0.01, inplace=True)
    (8): Linear(in_features=1164, out_features=1036, bias=True)
    (9): LeakyReLU(negative_slope=0.01, inplace=True)
    (10): Linear(in_features=1036, out_features=908, bias=True)
    (11): LeakyReLU(negative_slope=0.01, inplace=True)
    (12): Linear(in_features=908, out_features=780, bias=True)
    (13): LeakyReLU(negative_slope=0.01, inplace=True)
    (14): Linear(in_features=780, out_features=652, bias=True)
    (15): LeakyReLU(negative_slope=0.01, inplace=True)
    (16): Linear(in_features=652, out_features=512, bias=True)
  )
)
-------------------------------------------
-------------------------------------------